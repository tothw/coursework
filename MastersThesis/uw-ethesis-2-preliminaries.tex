%======================================================================
\chapter{Preliminaries}
%======================================================================
This chapter gives background on the tools used in the main body of work. Most of this material, with possible exceptions being iterative rounding and the structure of stable matching instances, should be familiar to a student with comparable background to a Combinatorics and Optimization undergraduate at the University of Waterloo. We will emphasize the results in the covered areas that we will need later, but it is important to point out that these areas go much deeper than what is written here and so the end of each section includes suggested texts for further reading.

\section{Matching Theory}
\subsection{Graphs and Matchings}
\paragraph{Graphs} A graph $G$ is an ordered pair $(V,E)$ where $V$ is called the vertex set and $E \subseteq \{\{a,b\} : a,b \in V, a \neq b\}$ is called the edge set. The clause $a \neq b$ forbids self-loops and insisting that $E$ is a proper set forbids parallel edges. Some authors choose to work with more generality but for ease of exposition we will not. As defined above, $G$ is an undirected graph, but if one were to change $E$ to a set of ordered pairs in $V \times V$ then $G$ would be called a directed graph. We will work here with undirected graphs in most chapters. When $V$ and $E$ are not explicit we can used $V(G)$ and $E(G)$ to refer to respectively the vertex and edge sets of $G$.
\paragraph{Paths and Adjacency} In a graph $G$, two vertices $a,b \in V(G)$ are said to be adjacent, denoted $a \sim b$, if $ab \in E$ (notice $ab \in E$ is shorthand for $\{a,b\} \in E$). For any vertex $a$ we call $\delta(a) = \{b \in V(G): b \sim a\}$ the neighbourhood of $a$. The degree of $a$, $d(a)$, is defined as $d(a) = |\delta(a)|$. A path $P \subseteq E$ is a set of edges that describe a sequence of vertices $v_0, v_1, \dots, v_n$ such that for any $i \in \{0,\dots, n-1\}$, $v_iv_{i+1} \in P$. That is a path is a set of edges describing a sequence of adjacent vertices. A cycle is a path with $v_0 = v_n$.
\paragraph{Bipartite Graphs} A graph $G = (V,E)$ is said to be bipartite if there exists a partition of $V$ into $V_0, V_1$ such that for every edge $ab \in E$, $a \in V_0$ and $b \in V_1$. We will restrict our attention to bipartite graphs in this section as most of our work on stable matchings presupposes this case.
\paragraph{Matching} Given a graph $G = (V,E)$, a matching on $G$ is any $M \subseteq E$ satisfying that for all $e_1, e_2 \in M$, $e_1 \cap e_2 = \emptyset$. We use $V(M) = \{v \in V: \exists e \in M, v \in e\}$ to denote the set of vertices matched in $M$. Intuitively our definition of matching means that each vertex matched in $M$ (those in $V(M)$) is matched to exactly one "partner" (ie $|\delta(v) \cap M| = 1$). The partner of vertex $v$, denoted $M(v)$, is the vertex such that $vM(v) \in M$. When it is clear from contex we may also use $M$ to refer to the graph "induced" by $M$, by which we mean the graph $(V(M), M)$.
\subsection{Maximum Cardinality Matching}
\paragraph{Problem} One classical problem in Matching Theory is the question of finding a maximum cardinality matching given a graph. This question was first was investigated by Berge in TODOCITE. He gave a characterization of when a matching isa maximum. To understand the theorem statement we will need just a bit more definitions.
\paragraph{Alternating Paths} A path $P$ in graph $G$ is said to be $M$-alternating for matching $M$ if its sequence of edges alternate being in $M$ and not being in $M$. More precisely if we order the edges of $P$ as $e_0, \dots, e_{n}$ then for any $i \in \{0, \dots, n-1\}$, edge $e_i \in M$ if and only if $e_{i+1} \in E \backslash M$. An $M$-alternating path $P$ is called $M$-augmenting if the first and last edges of $P$ are not in $M$. The name purposefully evokes the image of flow augmenting paths in network flow theory as there is a way to increase the cardinality of a matching $M$ by augmenting (taking symmetric difference, defined below) it with an $M$-augmenting path.
\paragraph{Symmetric Difference} For any sets $S,T \subseteq U$ the symmetric difference of $S$ and $T$, denoted $S \triangle T$, is given by $S \triangle T = (S \cup T) \backslash (S \cap T)$. 
\paragraph{Augmenting Path Theorem (Berge TODOCITE)} A matching $M$ in graph $G$ is maximum if and only if there does not exist any $M$-augmenting path $P$.
\paragraph{Proof} First suppose to the contrary that there exists $M$-augmenting path $P$. We claim that $M \triangle P$ is a matching of greater cardinality than $M$. To see that $M \triangle P$ is a matching let $v \in V(M \triangle P)$. If $v \in V(M)$ and $v \not\in V(P)$ then the edge incident upon $v$ has not changed, and no new edges incident to $v$ were added by symmetric difference with $P$. If $v \in V(M)$ and $v \in V(P)$ then as $P$ is an $M$-augmenting path, $vM(v) \in P$. Hence $vM(v) \notin M \triangle P$, and further there is $u \in V(G)$ such that $vu \in P\backslash M$. Thus $|\delta(v) \cap (M\triangle P)| =1$) as desired. Lastly if $v \not\in V(M)$ then $v$ is one of the endpoints of $P$ and is matched along its edge in $P$. So $M \triangle P$ is a matching. Further since every vertex in $V(M)$ is matched in $M \triangle P$, and the start and end vertices of $P$ are also matched, $M \triangle P$ matches more vertices that $M$ and thus is of greater cardinality.
\paragraph{}
Now suppose that $M$ is a matching which is not of maximum cardinality. That is there exists some matching $M'$ such that $|M'| > |M|$. Consider their symmetric difference $J = M' \triangle M$. Observe that each vertex in the graph $(V(G), J)$ has degree at most two (attaining this if it is matched along difference edges in $M$ and $M'$). Therefore $(V(G), J)$ consists only of vertex disjoint paths and cycles. The edges of said paths and cycles alternate belonging to $M'$ and to $M$ (observe that if this claim were to fail there would be a vertex with two edges incidenct upon it in the same matching, a contradiction). So the cycles are even in number of edges and contain the same number of edges from each of $M'$ and $M$. But since $|M'| > |M|$ there is a path with more edges in $M'$ than in $M$, $P$. This follows from counting edges in $M$ and $M'$ noticing that cycles contribute the same number to each. The path $P$ is $M$-augmenting. $\blacksquare$
\paragraph{}
We cover this proof not only because it is instrinsically interesting, but also because the structure of $J$, the symmetric difference of two matchings, will arise in the future when we study the structure of stable matchings.
\paragraph{Further Reading}
This problem is very well understood. For instance Tutte's classic min-max theorem TODOCITE, and Edmond's Blossom algorithm TODOCITE. A textbook appropriate for advanced undergraduate or beginner graduate students is Combinatorial Optimization by Cook, Cunningham, Pulleybank, and Schrijver TODOCITE which contains a chapter covering the results mentioned here.
\subsection{Maximum Weight Matching}
\paragraph{Problem} Suppose we are given a graph $G$ and a weight function $w : E(G) \rightarrow \R$. The problem now is to find a matching $M$ which maximizes $\sum_{e \in M} w(e)$. This problem and its solution via the Hungarian Algorithm attributed to Kuhn and Munkres TODOCITE is one of the earliest success stories of Combinatorial Optimization. Another approach which gives some flavour of the work to come is to model the problem via a linear program. It is this approach we will explain here.
\paragraph{Linear Program}
If you are uncomfortable with linear programming please see section X.Y TODOCITE, otherwise read on. Consider the following linear program:
\begin{align*}
	\text{max} &\sum_{e \in E(G)} w(e) x_e \\
	\ni \sum_{e \in \delta(v)} x_e &\leq 1 &\text{for all $v \in V(G)$} \\
	x_e &\geq 0 &\text{for all $e \in E(G)$.}
\end{align*}
If we let $M$ be a maximum weight matching of $G$ with weight function $w$ then its incidence vector $\chi(M) \in \R^{|E(G)|}$ is the vector with $\chi(M)_e = 1$ if $e \in M$ and $\chi(M)_e = 0$ otherwise. Since $M$ is a matching $\chi(M)$ is feasible for the above linear program. Hence the optimal solution to the linear program is an upper bound on the maximum weight of a $M$ in $G$. In fact Birkhoff TODOCITE showed that all extreme point solutions to this program are integral and hence optimal extreme point solutions are incidence vectors of matchings. TODOCITE (Edmonds should be here somewhere). In the next section we will break down the previous statement and discuss a proof, not the original proof of Birkhoff, but a proof using the techniques of iterative rounding.
\section{Iterative Rounding}
\paragraph{}
The technique of iterative rounding was originally inspired by Jain's work on survivable network design TODOCITE. Since that time it has proven to be a versatile technique seeing application across a wide variety of branches of Combinatorial Optimization including Matchings, Spanning Trees, Flows, and Network Design TODOCITE to name a few. Iterative Rounding was initially studied as a procedure for obtaining approximation algorithms TODOCITE, but has since been adapted to reprove many classical results TODOCITE. The earliest known use of iterative rounding for exact optimization problems was given by Steinitz in his study of rearrangements TODOCITE. It is this latter application to proofs of integrality that we will focus on, but in the context of matching. We will begin with some necessary background from the theory of linear programming, then proceed to discuss the general form the iterative rounding technique takes in the context we are studying, and finish by demonstrating its application to maximum weight bipartite matching.
\subsection{Linear Programming Tools}
\paragraph{}
Linear programming has proven to be a powerful and unifying tool in combinatorial optimization TODOCITE. In this section we will review the fundamentals of linear programming theory and discuss results necessary for application to iterative rounding. For a comprehensive treatment of linear programming consider the classic text of Chvatal TODOCITE.
\paragraph{Basic Definitions}
Let $A$ be an $m \times n$ matrix, let $b \in \R^m$ and let $c \in \R^n$. The goal of a standard linear programming problem is to find $x \in \{x \in \R^n : Ax \leq b, x \geq 0 \}$ which maximizes $c^Tx$. This is commonly written in the compact form $\max\{c^Tx : Ax \leq b, x \geq 0 \}$ or displayed as
\begin{align*}
\max\quad &c^Tx \\
Ax &\leq b \\
x &\geq 0.
\end{align*}
The linear function $c^Tx$ is referred to as the objective function in variables $x$. Given any row $a_i$ of $A$ and the corresponding $b_i$ entry of $b$, $a_i^Tx \leq b_i$ is a constraint. The constraints $x \geq 0$ (shorthand for $x_i \geq 0$ for all $i \in \{1, \dots, n\}$) are called non-negativity constraints. The choice of the above standard form eases exposition, especially when we talk about duality, but it is by no means rigid. If one wishes to apply a constraint of the form $a^T x = b$ or $a^T x \geq b$, or even finishes to be free of non-negativity constraints then such a linear program could be written down and converted to an equivalent program (possible with more variables) in standard form. To see how to do this reference Chvatal TODOCITE, or try it as an easy exercise.
\paragraph{Geometry} Given a linear program in standard form $P = \{ x \in \R^n: Ax \leq b, x \geq 0 \}$ is referred to as the feasible region since it describes the space of vectors which satisfy the constraints of the linear program. Such $P$ is a geometric object called a polyhedron, which can be described as the space formed by the intersection of a finite number of half-spaces. A polyhedron is unbounded if there exists $d \in \R^n\backslash \{0\}$ such that for all $\alpha \in \R$ with $\alpha \geq 0$ and $x \in P$, $x + \alpha d \in P$. Inuitively this says unbounded polyhedra have directions in which any point in the polyhedron can be translated arbitrarily far along and remain in the polyhedron. A polyhedron which is not unbounded is called bounded, and such polyhedra are called polytopes. Observe that if $P$ is unbounded the corresponding linear program may not have a finite optimal value. In particular this happens when translating along a direction $d$ can increase the objective value, that is for $x \in P$ we have the situation $c^T(x + \alpha d) > c^Tx$. It should be intuitive from the geometry that linear programs whose feasible regions are polytopes always have finite optimal values, but for the critical reader who needs a proof I refer you to Chvatal TODOCITE.
\paragraph{Extreme Points and Basic Feasible Solutions}
A vector $x \in P$ is called an extreme point if there does not exist distinct $y^1, y^2 \in P$ such that $x$ is a convex combination of $y^1, y^2$. Precisely there does not exists $y^1 \neq y^2 \in P$ such that $x = \frac{1}{2} y^1 + \frac{1}{2}y^2$. A vector $x \in P$ is called a basic feasible solution if there exists $n$ linearly independent rows of $A$, say $a_1, \dots, a_n$ (not necessarily the first $n$ rows of $A$), with corresponding entries of $b$: $b_1, \dots, b_n$ satisfying $a_i^T x = b_i$ for all $i\in \{1,\dots, n\}$. It is not immediately obvious that extreme points and basic feasible solutions are equivalent, but in the following lemmas we will build of theory showing the surprising fact that they are.
\paragraph{Proof}

\subsection{Strategy}
\subsection{Application to Matching}
\section{Stable Matching}
\subsection{Problem}
\subsection{Gale Shapley Algorithm}
\subsection{Structure}

