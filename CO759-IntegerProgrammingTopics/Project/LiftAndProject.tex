\documentclass{beamer}

\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary[topaths]
\usepackage{comment}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\proj}{proj}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\author{Paper By: Bodur, Dash, and G\"{u}nl\"{u}k\\
Presentation by: William Justin Toth}
\institute{University of Waterloo}
\date{April 8, 2016}
\title{A New Lift-and-Project Operator}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\AtBeginSubsection[]
{
	\begin{frame}<beamer>
		\frametitle{Outline}
		\tableofcontents[currentsection, currentsubsection]
	\end{frame}
}

\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}

\section{Introduction}

\begin{frame}
\frametitle{A fundamental goal}
Consider a $0$-$1$ mixed integer set \alert{$P^{IP}$} defined by:
$$\alert{P^{IP} := P \cap \{0,1\}^{n_1} \times \R^{n_2}}.$$
Where $\alert{P = \{x \in \R^n : Ax = b \}}$ is a polyhedron, and $\alert{n = n_1+ n_2}$.
\\\ \\
A central question in Integer Programming: Find a better approximation of $\alert{\conv(P^{IP})}$ than its linear relaxation $\alert{P}$.
\end{frame}

\begin{frame}
\frametitle{One approach}
We can define a hierarchy of relaxations $\alert{H^1, \dots, H^{n_1}}$ of $\alert{P^{IP}}$ such that
$$\alert{P \supseteq H^1 \supseteq \dots \supseteq H^{n_1} = \conv(P^{IP})}.$$
Two examples we will discuss: Lov\'asz-Schrijver and Sherali-Adams.\\
$\textbf{New contribution:}$ An operator which obtains $\alert{\conv(P^{IP})}$ in $\alert{\ceil{\frac{n_1}{2}}}$ steps instead of $\alert{n_1}$.
\end{frame}

\begin{frame}
\frametitle{Preliminaries: Extended LP formulations}
$\alert{Q = \{(x,y) \in \R^n \times \R^q : Cx + Dy \leq g \}}$ is called an $\textit{extended formulation}$ of $\alert{P}$ if
$$\alert{P = \proj_x(Q)}.$$
Where $\alert{proj_x(Q)}$ denotes the orthogonal projection of $\alert{Q}$:
$$\alert{\proj_x(Q) = \{x \in \R^: \exists y \in \R^q \text{ s.t. } (x,y) \in Q\}}.$$ 
In this talk we call $\alert{Q}$ an $\textit{extended LP formulation}$ of $\alert{P^{IP}}$.
\end{frame}

\begin{frame}
\frametitle{Preliminaries: $0$-$1$ Split cuts}
 For $\alert{i \in I = \{1, \dots, n_1\}}$ define the $0$-$1$ $\textit{split set}$:
 $$\alert{S_i = \{x \in \R^n : 0 < x_i < 1\}}.$$
 Inequality $\alert{c^Tx \geq d}$ is a $0$-$1$ $\textit{split cut}$ generated by $\alert{S_i}$ if it is valid for $\alert{\conv(P\backslash S_i)}$.
 \\\ \\
 We define $0$-$1$ $\textit{split closure}$ of $\alert{P}$ as
 $$\alert{S(P) = \bigcap_{i \in I} \conv(P \backslash S_i)}.$$
\end{frame}

\begin{frame}
\frametitle{Preliminaries: Notes on Split Closure}
$\alert{S(P)}$ is a polyhedron. So $\alert{S}$ can be applied iteratively.
\\\ \\
Define $\alert{S^k(P)}$ as follows:
\begin{itemize}
\item $\alert{S^0(P) = P}$,
\item $\alert{S^k(P) = S(S^{k-1}(P))}$ for $\alert{k \geq 1}$.
\end{itemize}
Theorem (Balas): $\alert{S^{n_1}(P) = \conv(P^{IP})}$.
\end{frame}

\section{Lov\'asz-Schrijver}

\begin{frame}
\frametitle{Lift-and-Project operators}
All Lift-and-Project operators are based on a common scheme:
\begin{enumerate}
\item $\textbf{Lift:}$ Create an extended formulation of $\alert{P}$.
\item $\textbf{Strengthen:}$ Perform a strengthening of the extended formulation by adding cuts.
\item $\textbf{Project:}$ Project the strengthened formulation onto the original space.
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Lov\'asz-Schrijver operator - Lift step}
Let $\alert{(a^\ell)^Tx \leq b^\ell}$, $\alert{\ell \in L = \{1, \dots, m\}}$ be the inequalities in $\alert{Ax \leq b}$. Going forward we assume $\alert{0 \leq x_i \leq 1}$ is included in $\alert{Ax \leq b}$ for each $\alert{i \in I = \{1,\dots,n_1\}}$.
\\ We start with the quadratic inequalities:
\begin{align*}
\alert{x_i(b^\ell - (a^\ell)^Tx) \geq 0}, &\text{ for all } \alert{i\in I,\ \ell \in L} \\
\alert{(1-x_i)(b^\ell - (a^\ell)^Tx) \geq 0}, &\text{ for all }\alert{ i\in I,\ \ell \in L} \\
\end{align*}
\end{frame}
\begin{frame}
\frametitle{Lov\'asz-Schrijver operator - Lift step cont'd}
We linearize each  quadratic term $\alert{x_{i}x_{j}}$ by replacing with variable $\alert{y_{ij}}$.\\
Let $\alert{\hat{M}(P)}$ be the set obtained after the Lift step, it satisfies:
\begin{align*}
\alert{b^\ell x_i - \sum_{j=1}^n a_j^\ell y_{ij} \geq 0}, &\text{ for all } \alert{i \in I,\ \ell \in L} \\
\alert{b^\ell - \sum_{j = 1}^n a^\ell_j x_j - b^\ell x_i + \sum_{j = 1}^n a_j^\ell y_{ij} \geq 0}, &\text{ for all } \alert{i \in I,\ \ell \in L} \\
\alert{y_{ij} = y_{ji}}, &\text{ for all } \alert{i<j,\ i,j \in L}
\end{align*}
\end{frame}

\begin{frame}
\frametitle{Lemma: $\hat{M}(P)$ is an extended LP formulation of $P^{IP}$}
$\textbf{Proof Idea:}$ Fix $\alert{i, \ell}$. Adding inequalities:
$$\alert{b^\ell x_i - \sum_{j=1}^n a_j^l y_{ij} \geq 0} \text{ and } \alert{b^\ell -\sum_{j=1}^n a_j^\ell x_j - b^\ell x_i + \sum_{j=1}^n a_j^\ell y_{ij} \geq 0},$$
We obtain that $$\alert{b^\ell -(a^\ell)^Tx \geq 0}.$$
Therefore $\alert{\proj_x(\hat{M}(P)) \subseteq P}$.
\end{frame}

\begin{frame}
\frametitle{Lemma: $\hat{M}(P)$ is an extended LP formulation of $P^{IP}$}
$\textbf{Proof Continued:}$ Now let $\alert{\bar{x} \in P}$. Define $$\alert{\bar{y}=(x_i x_j : i \in I, j \in \{1, \dots, n\})}.$$
Then the values of $\alert{\hat{M}}$ inequalities left hand sides are equal to:
$$\alert{\bar{x}_i (b^\ell - (a^\ell)^T \bar{x})} \text{ and } \alert{(1-\bar{x}_i )(b^\ell - (a^\ell)^T \bar{x})}.$$
These are clearly non-negative as $\alert{\bar{x}}$ satisfies $\alert{0 \leq \bar{x} \leq 1}$ and $\alert{A \bar{x} \leq b}$.\\
Therefore $\alert{\proj_x(\hat{M}(P)) = P}$.\\$\blacksquare$
\end{frame}

\begin{frame}
\frametitle{Lov\'asz-Schrijver operator - Strengthen and Project steps}
We strengthen $\alert{\hat{M}(P)}$, obtaining the set $\alert{M(P)}$ as follows:
$$\alert{M(P) = \hat{M}(P) \cap \{ (x,y) : y_{ii} = x_{i},\ \forall i \in I\} } $$
Finally the strengthening of $\alert{P}$ after projection is given by:
$$\alert{N(P) = \proj_x(M(P))}$$
$\textbf{Note:}$ $\alert{P^{IP} \subseteq N(P)}$ as for all $\alert{\bar{x} \in P^{IP}}$ and $\alert{i \in I}$, 
$$\alert{\bar{x}_i^2 = \bar{x}_i}$$
\end{frame}

\begin{frame}
\frametitle{Lemma: For any $i\in I$, $y_{ii} = x_{i}$ is valid for $S(\hat{M}(P))$} 
$\textbf{Proof Idea:}$ From our quadratic inequalities, the $\textit{McCormick Inequalities}$ are valid for $\alert{\hat{M}(P)}$:
\begin{align*}
\alert{x_i x_j \geq 0} & \rightarrow \alert{y_{ij} \geq 0} \\
\alert{x_i(1-x_j)\geq 0} & \rightarrow \alert{x_i \geq y_{ij}} \\
\alert{(1-x_i)x_j \geq 0} & \rightarrow \alert{x_j \geq y_{ij}} \\
\alert{(1-x_i)(1-x_j) \geq 0} & \rightarrow \alert{1 - x_i - x_j + y_{ij}  \geq 0}
\end{align*}
Thus $\alert{x_i = 0} \implies \alert{y_{ij} = 0}$ and $\alert{x_i = 1} \implies \alert{y_{ij} = x_j}$. So if $\alert{x_i = 0}$ or $\alert{x_i = 1}$ then
$$\alert{y_{ii} = x_i}$$ \\$\blacksquare$
\end{frame}

\begin{frame}
\frametitle{New operator - Strengthening Lov\'asz-Shrijver}
Previous Lemma suggests that $\alert{M(P)}$ is obtained from $\alert{\hat{M}(P)}$ by adding one split cut for each $\alert{S_i}$, $\alert{i \in I}$.\\\ \\
What if instead we added all $0$-$1$ split cuts?\\
We'd obtain the new operator:
$$\alert{\tilde{N}(P) = \proj_x(S(\hat{M}(P)))}$$
Notice our Lemma gives $\alert{S(\hat{M}(P)) \subseteq M(P)}$ which implies:
$$\alert{\tilde{N}(P) \subseteq N(P)}$$
\end{frame}

\begin{frame}
\frametitle{Theorem: $S(\hat{M}(P)) \subseteq M(S(P))$}
Says new operator's strengthened extension of $\alert{P}$ is stronger than Lov\'asz-Schrijver's of $0$-$1$ split closure of $\alert{P}$.
\\$\textbf{Proof Idea:}$ Observe that $$\alert{M(S(P)) = \hat{M}(S(P)) \cap \{(x,y):y_{ii} = x_i, \forall i \in I\}}$$
Lemma implies $$\alert{S(\hat{M}(P)) \subseteq \{(x,y):y_{ii}=x_i, \forall i \in I \}}$$  and it is easy to see from straightforward computation that $$\alert{S(\hat{M}(P)) \subseteq \hat{M}(S(P))}.$$ 
\end{frame}

\begin{frame}
\frametitle{Some Corollaries}
Consequences of $\textbf{Theorem:}$ $\alert{S(\hat{M}(P)) \subseteq M(S(P))}$:
\begin{itemize}
\item By projecting onto space of $\alert{x}$ variables: $$\alert{\tilde{N}(P) \subseteq N(S(P))}$$
\item Since $\alert{N(S(P)) \subseteq S(S(P))}$ new operator obtains convex hull in half the steps: $$\alert{(\tilde{N})^{\ceil{\frac{n_1}{2}}}(P) = \conv(P^{IP})}$$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Sherali-Adams level $k$ operator - Lift Step}
Define $\alert{PSA^k(P)}$ by, for each inequality $\alert{b^\ell - (a^\ell)^Tx \geq 0}:$
$$\alert{\prod_{i \in J_1} x_i \prod_{j \in J_2} (1 - x_j) (b^\ell - (a^\ell)^Tx) \geq 0}$$
for all $\alert{(J_1, J_2)}$ ``pairs of order $k$".\\
$\textbf{pair of order k:}$ $\alert{J_1, J_2 \subseteq I}$, $\alert{|J_1 \cup J_2| = k}$, and $\alert{J_1 \cap J_2 = \emptyset}$.
\end{frame}

\begin{frame}
\frametitle{Sherali-Adams level $k$ operator - Lift Step cont'd}
Let $\alert{\mathcal{T}}$ be set of tuples with $\alert{\leq k+1}$ indices. Then $\alert{\exists T(J_1,J_2,\ell) \subseteq \mathcal{T}}$, we may rewrite:
$$\alert{\prod_{i \in J_1} x_i \prod_{j \in J_2} (1 - x_j) (b^\ell - (a^\ell)^Tx) \geq 0}$$
as
$$ \alert{\beta - \sum_{S \in T(J_1, J_2,\ell)} (\alpha_S \prod_{j=1}^{|S|} x_{S_j}) \geq 0}$$
which can be linearized to obtain $\alert{ESA^k(P)}$:
$$\alert{\beta -\sum_{S \in T(J_1, J_2,\ell)} \alpha_S y_S \geq 0} $$
$\text{ for all } \alert{\ell \in L},\ \alert{(J_1, J_2)} \text{ pairs of order } \alert{k}$
\end{frame}

\begin{frame}
\frametitle{Sherali-Adams level $k$ operator - Strengthen and Project Steps}
For $\alert{S \in \mathcal{T}}$ let $\alert{[S]}$ be tuple of unique elements of $\alert{S}$ in same order.\\
$\textbf{Example:}$ For $\alert{k=2}$, $\alert{S = (1,1,2)}$ gives $\alert{[S] = (1,2)}$.\\
To strengthen create $\alert{LSA^k(P)}$ by adding to $\alert{ESA^k(P)}:$
$$\alert{y_S = y_{[S]} \quad} \text{for all } \alert{S \in \mathcal{T}}$$
$\textbf{Sherali-Adams operator:}$ $\alert{SA^k(P)}$ given by $\textit{projecting}$ $\alert{ESA^k(P)}$ onto the space of variables $\alert{y_{(1)} ,\dots y_{(n)}}$. Notice each $\alert{y_{(i)} = x_i}$.
\end{frame}

\begin{frame}
\frametitle{Sherali-Adams example}
For $\alert{k=1}$, $\alert{SA^k(P)}$ is simply $\alert{N(P)}$, so let's consider $\alert{k=2}$.\\
First $\alert{PSA^2(P)}\textbf{:}$
\alert{\begin{align*}
x_ix_j(b^\ell -(a^\ell)^Tx \geq 0,&\ &\forall i<j \in I, \ell \in L \\
x_i(1-x_j)(b^\ell -(a^\ell)^Tx \geq 0,&\ &\forall i\neq j \in I, \ell \in L \\
(1-x_i)(1-x_j)(b^\ell -(a^\ell)^Tx \geq 0,&\ &\forall i<j \in I, \ell \in L \\
\end{align*}}
Second obtain $\alert{ESA^2(P)}$ by replacing each $\alert{x_ix_jx_k}$ with $\alert{y_{(i,j,k)}}$, $\alert{x_ix_j}$ with $\alert{y_{(i,j)}}$, and $\alert{x_i}$ with $\alert{y_{(i)}}$.\\
Then obtain $\alert{LSA^2(P)}$ by replacing each $\alert{y_{(i,i,k)}}$ and $\alert{y_{(i,k,k)}}$ with $\alert{y_{(i,k)}}$, and $\alert{y_{(i,i)}}$ with $\alert{y_{(i)}}$.
\end{frame}

\begin{frame}
\frametitle{Some Lemmas}
The following observations about the Sherali-Adams operator are analogous to those we observed regarding Lovasz-Schrijver:\\
\begin{itemize}
\item$\textbf{Lemma 1:}$ For any $\alert{k \geq 1}$, $\alert{ESA^k(P)}$ is an extended LP formulation of $\alert{P^{IP}}$.
\item$\textbf{Lemma 2:}$ For any $\alert{S \in \mathcal{T}}$, $\alert{y_S = y_{[S]}}$ is a $0$-$1$ split cut for $\alert{ESA^k(P)}$.
\end{itemize}
\end{frame}
\begin{frame}
\frametitle{Comparing new operator to level-2 Sherali-Adams}
$\textbf{Theorem:}$ $\alert{SA^2(P) \subseteq \tilde{N}(P)}$\\
$\textbf{Proof Sketch:}$
\begin{itemize}
\item Recall: $\alert{\hat{M}(P)}$ defined on variables $\alert{x = (x_i : i \in I)}$ and $\alert{y = (y_{ij}: i \in I, j \in J)}$
\item So $\alert{M(\hat{M}(P))}$ defined on variables $\alert{v_{i,jk}}$ (representing products $\alert{x_iy_{jk}}$) in addition to $\alert{x's}$ and $\alert{y's}$
\item Since $\alert{\proj_{(x,y)}(M(\hat{M}(P))) \subseteq S(\hat{M}(P))}$ we have $\alert{\proj_x (M(\hat{M}(P))) \subseteq \proj_x (S(\hat{M}(P))) = \tilde{N}(P)}$.
\end{itemize}
(So just need to show $\alert{SA^2(P) \subseteq \proj_x(M(\hat{M}(P)))}$)
\end{frame}

\begin{frame}
\frametitle{Proof continued - show $\alert{SA^2(P) \subseteq \proj_x(M(\hat{M}(P)))}$}
\begin{itemize}
\item Let $\alert{\hat{x} \in SA^2(P)}$. Then $\alert{\exists \hat{y} = (\hat{y}_S : S \in \mathcal{T}) \in LSA^2(P)}$ such that each $\alert{\hat{x}_i = \hat{y}_{(i)}}$.
\item Construct $\alert{(\tilde{x},\tilde{y},\tilde{z}) \in M(\hat{M}(P))}$ as follows:
\begin{itemize}
\item $\alert{\tilde{x}_i = \hat{y}_{(i)} = \hat{x}_i}$
\item $\alert{\tilde{y}_{ij} = \hat{y}_{(p,q)}}$ where $\alert{p \leq q}$ and $\alert{\{p,q\} = \{i,j\}}$
\item $\alert{\tilde{v}_{i,jk} = \hat{y}_{(p,q,r)}}$ were $\alert{p \leq q \leq r}$ and $\alert{\{p,q,r\} = \{i,j,k\}}$
\end{itemize}
\item Finish showing $\alert{(\tilde{x},\tilde{y}, \tilde{v}) \in M(\hat{M}(P))}$ by case analysis on types of inequalities defining $\alert{M(\hat{M}(P))}$
\end{itemize}
$\blacksquare$
\end{frame}

\begin{frame}
\frametitle{Application to Stable Set Polytope}
$\textit{Stable set polytope}$ of graph $\alert{G = (V,E)}$ is convex hull of incidence vectors of independent sets:
$$\alert{STAB(G) = \conv(\{x \in \{0,1\}^{|V|} : x_i + x_j \leq 1,\ \forall \{i,j\} \in E\})}$$
Linear programming relaxation is called $\textit{fractional stable set polytope}$:
$$\alert{FSTAB(G) = \{x \in \R^{|V|} : x_i + x_j \leq 1,\ \forall \{i,j\} \in E;\ 0 \leq x_i \leq 1,\ \forall i \in V\}}$$
\end{frame}

\begin{frame}
\frametitle{Stable Set Polytope shows bounds are tight}
From our previous results we have a hierarchy of relaxations:
$$\alert{STAB(G) \subseteq SA^2(P) \subseteq \tilde{N}(P) \subseteq N^2(P) \subseteq N(P) \subseteq P = FSTAB(G)}$$
with $\alert{\tilde{N}(P) \subseteq N^2(P)}$ following from $\alert{\tilde{N}(P) \subseteq N(S(P))}$.\\
\ \\
$\textbf{Lemma:}$ If $\alert{G = K_n}$ and $\alert{P = FSTAB(G)}$, then $\alert{SA^2(P) = N^2(P)}$.\\
\ \\
In other words the containment bounds on the new operator $\alert{\tilde{N}}$ are tight.
\end{frame}

\begin{frame}
\frametitle{A question}
But can we also demonstrate cases where the containment $\alert{SA^2(P) \subseteq \tilde{N}(P) \subseteq N^2(P)}$ is strict?\\\ \\
$\textbf{Answer:}$ Yes we can! We can do this via some computational experiments.\\\ \\
But first we will need to be able to optimize over the polyhedra our operators give us.
\end{frame}

\begin{frame}
\frametitle{Stable Set Polytope - Optimizing over Extended Formulations}
$\textbf{Theorem:}$(Balas) For $0$-$1$ split closure $\alert{S(P)}$ there is an extended formulation polynomial in the size of the encoding of $\alert{P}$.\\
$\textbf{Theorem:}$ (Lov\'asz and Schrijver) For $\alert{P = FSTAB(G)}$, $$\alert{N(P) = S(P) = P \cap \{x \in \R^{|V|} : \sum_{i \in C} x_i \leq \frac{|C|-1}{2},\ \forall C \in \mathcal{O}\mathcal{C}\}}$$
where $\alert{\mathcal{O}\mathcal{C}}$ is the set of all odd cycles in $\alert{G}$.
\begin{itemize}
\item Can write $\alert{\hat{M}(P)}$ explicitly, first result then says we can optimize over $\alert{S(\hat{M}(P))}$. Use this for $\alert{\tilde{N}(P)}$
\item $2$nd result lets us write $\alert{M(N(P))}$ explicity. Use that for $\alert{N^2(P)}$
\item (Ostrowski) In special cases like $\alert{FSTAB}$ we can optimize over $\alert{SA^k(P)}$ for $\alert{k\leq 3}$.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Stable Set Polytope - Experimental Procedure}
We compare the strength of relaxations $\alert{SA^2(P)}$, $\alert{\tilde{N}(P)}$, $\alert{N^2(P)}$, and $\alert{N(P)}$ for $\alert{STAB(G)}$ for randomly generated graphs $\alert{G}$.\\\ \\
For each relaxation $\alert{R}$ we measure the gap closed as:
$$ \alert{100 \frac{(z_{LP} - z_{R})}{(z_{LP} - z_{IP})}}$$
where $\alert{z_R = \max\{c^Tx:x \in R\}}$.\\\ \\
IBM ILGO Cplex 12.4 is used as the LP/MILP solver.
\end{frame}

\begin{frame}
\frametitle{Stable Set Polytope - Experimental Procedure}
Tests done on randomly generated instances as follows:
\begin{itemize}
\item Graphs are generated randomly with number of vertices $\alert{|V| \in \{20,30,40,50\}}$ and average density $\alert{D \in \{0.25,0.50,0.75\}}$. 
\item For each $\alert{(D,|V|)}$ pair $\alert{5}$ graphs are generated
\item For each graph, $\alert{5}$ different objective functions with coefficients randomly chosen from $\alert{\{0,1,\dots,10\}}$ are generated
\item That is $\alert{25}$ instances for each $\alert{(D,|V|)}$ pair are solved.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Stable Set Polytope - Experimental Results}
\centering
Average difference in gap closed percentages:

\begin{tabular}{c c | c c c c c}
\hline
\rule{0pt}{4ex}$D$ &$|V|$ & $N$ & $N^2 - N$ & $\tilde{N} - N^2$ & $SA^2 - \tilde{N}$ & Remaining \\ \hline
0.25 & 20 & 100 & 0 & 0 & 0 & 0 \\ 
 & 30 & 97.5086 & 2.4914 & 0 & 0 & 0 \\ 
& 40 & 89.4596 & \alert{10.3762} & \alert{0.0843} & \alert{0.0003 }& 0.0796 \\ 
& 50 & 80.55.25 & \alert{18.3314} & \alert{0.0862} & \alert{0.0001} & 1.0299 \\ \hline
0.5 & 20 & 80.2491 & 19.3807 & 0.0073 & 0 & 0.3628 \\
& 30 & 66.7573 & 27.8776 & 0 & 0 & 5.4542 \\
& 40 & 58.3730 & 29.1865 & 0 & 0 & 12.4404 \\
& 50 & 51.8947 & 25.9474 & 0 & 0 & 22.1579 \\ \hline
0.75 & 20 & 61.2747 & 27.8776 & 0 & 0 & 10.8476 \\
& 30 & 50.4497 & 25.2249 & 0 & 0 & 24.3254 \\
& 40 & 46.3941 & 23.1971 & 0 & 0 & 30.4088 \\
& 50 & 43.9074 & 21.9537 & 0 & 0 & 34.1389 \\ \hline
\end{tabular}
\end{frame}

\begin{frame}
\frametitle{Takeways}
\begin{itemize}
\item Classic lift-and-project operators $\alert{N(P)}$ and $\alert{SA^k(P)}$ can be thought of as adding specific sets of $0$-$1$ split cuts to extended LP relaxations
\item Using this insight we can create a new operator, $\alert{\tilde{N}(P)}$ by adding all $0$-$1$ split cuts to Lov\'asz-Schrijver's extended LP relaxation $\alert{\hat{M}(P)}$
\item This new operator is non-trivially stronger than $\alert{S(N(P))}$ (and in some cases $\alert{N^2(P)}$), but weaker than $\alert{SA^2(P)}$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Suggestions for Future Work}
Theoretical:
\begin{itemize}
\item What if we apply this idea to other lift-and-project operators? Maybe $\alert{\tilde{SA}^2(P) = \proj_x (S(ESA^2(P)))}$?
\item (Authors:) How do operators compare in terms of computational complexity instead of relative strength?
\item Can we make theoretical guarantees on bounds of ``gap closed"?
\end{itemize}
Practical:
\begin{itemize}
\item Theory was built in a $0$-$1$ MIP setting, so try experiments on MIP problems instead of $\alert{STAB}$ (pure IP). Possibly even use real-world data instead of randomly generated instances.
\item (Authors:) It would be interesting to investigage efficient methods for optimizing over $\alert{S(P)}$ and use those to build a more sophisticated implementation of $\alert{\tilde{N}(P)}$.
\end{itemize}
\end{frame}

\end{document}
