\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{bbm}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
\newcommand{\1}{\mathbbm{1}} 

\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 Assignment 9 - Problem Set 3} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section{}
\paragraph{}
Throughout we use the equivalence of Hamming distance and path length in $H(n,2)$ which we prove in question $2$ which follows.
\paragraph{}
Let $A_i$ denote the adjacency matrix of the $i$-th distance graph of the Hamming graph $H(n,2)$. Set $A_0 = I$. Let $i \in \{1, \dots, n\}$. Let $\alpha_i$ be given as
$$|\{x \in \Z^n_2 : h(u,x) = 1 \text{ and } h(x,v) = i-1\}| \quad \text{for any }u,v\text{ such that } h(u,v) = i$$
and let $\beta_i$ be given as
$$|\{x \in \Z^n_2 : h(u,x) = 1 \text{ and } h(x,v) = i+1\}| \quad \text{for any }u,v\text{ such that } h(u,v) = i.$$
That is, $\alpha_i$ counts the number of vertices adjacent to $u$ and at distance $i-1$ from $v$ for any pair $u,v$ of Hamming distance $i$, and $\beta_i$ similarly counts the number of vertices adjacent to $u$ and at distance $i+1$. We will show that $\beta_i$ and $\alpha_i$ are independent of our choice of $u,v$ and thus constants depending only on the parameter $n$ of our graph and on $i$.
\paragraph{}
As a matter of notation we will use $u \oplus v$ to denote addition in $\Z_2^n$ and leave $+$ denoting the usual addition over integers. One can think of $u \oplus v$ to be $u$ XOR $v$ (bitwise) when $u$ and $v$ are interpreted as bitstrings of length $n$. Let $|u| = \sum_k u_k$, that is $|u|$ counts the number of $1$'s in $u$.
\paragraph{}
Let $u, v \in \Z^n_2$ with $h(u,v) = i$ and let $x \in \delta(u)$. Recall that $\delta(u) = \{x \in \Z^n_2: x\sim u \in H(n,2)\}$. Then $x$ and $u$ differ in only one coordinate, so
$$x \oplus u = e_k$$
for some $k$, where $e_k$ denotes standard basis vector with $1$ in coordinate $k$. Then $e_k \oplus u = x$. Since $h(u,v) = i$, we have $|u \oplus v | = i$. We compute $h(x,v) = |x \oplus v|$:
\begin{align*}
|x \oplus v| &= |(e_k \oplus u) \oplus v|\\
&= |e_k \oplus (u \oplus v) | \\
&= \begin{cases}
i-1, \text{ if $(u \oplus v)_k = 1$}  \\
i+1, \text{ if $(u\oplus v)_k = 0$} .
\end{cases} 
\end{align*}
\paragraph{}
Thus $\alpha_i$ counts the number of $x = u \oplus e_k$ where $(u \oplus v)_k = 1$. Since $|u \oplus v| = i$ there are exactly $i$ such $k$ and hence $i$ such $x$. So $\alpha_i = i$. Further $\beta_i$ counts the number of $x = u \oplus e_k$ where $(u \oplus v)_k = 0$. Since there are $i$ coordinates valued $1$ in $(u\oplus v)$ there are $n-i$ coordinates valued $0$. So $\beta_i = n-i$. Therefore $\beta_i$ and $\alpha_i$ are well-defined and independent of our choice of $u$ and $v$.
\paragraph{}
Consider the $u,v$-th entry of $A_1A_{i}$, which is equal to $e_u^TA_1A_i e_v$. Observe that $(A_ie_v)_x = 1$ if $h(x,v) = i$ and is $0$ otherwise. Also $(e_u^TA_1)^T_x = 1$ if $x \in \delta(u)$ and is $0$ otherwise. Then we have
\begin{equation}e_u^TA_1A_ie_v = \sum_{x : x\in \delta(u)\text{ and } h(x,v) = i}1.\label{eq:xcount}\end{equation}
We claim that if (\ref{eq:xcount}) $> 0$ then $h(u,v) = i \pm 1$. To see this let $x \in \delta(u)$ such that $h(x,v) = i$. If $h(u,v) = i$ then the path from $u$ to $x$ to $v$ (via an $i$ length path), back to $u$ (via an $i$ length path) forms a cycle in $H(n,2)$ of length $2i+1$ which is odd. This cannot happen since $H(n,2)$ is bipartite (partitions are vertices with even number of ones and vertices with an odd number of ones; it is clear that changing one coordinate of an element of $\Z^n_2$ changes this parity and hence adjacent elements have differing parity in terms of number of ones). Now if $h(u,v) < i-1$ then the path from $x$ to $u$ to $v$ (via an $<i-1$ length path) is an $x$-$v$ path of length $< i$ contradicting $h(x,v) = i$. In the case $h(u,v) > i+1$ the path from $u$ to $x$ to $v$ (via an $i$ length path) is a $u$-$v$ path of length $i+1$ contradicting $h(u,v) > i+1$. Thus the claim $h(u,v) = i \pm 1$ if (\ref{eq:xcount}) $>0$ holds.
\paragraph{}
Let $c_i = \beta_{i-1}$ and $b_i = \alpha_{i+1}$. Suppose $(\ref{eq:xcount}) > 0$. If $h(u,v) = i-1$ then $(A_{i-1})_{u,v} = 1$, and $(\ref{eq:xcount})$ is precisely $\beta_{i-1}$ which counts the number of vertices adjacent to $u$ and at distance $i$ from $v$. Also observe that $(A_{i+1})_{u,v} = 0$ in this case. So we have
$$e_u^T A_1 A_i e_v = c_i (A_{i-1})_{u,v} + b_i(A_{i+1})_{u.v}.$$
Now if $h(u,v) = i+1$ then $(A_{i+1})_{u,v} = 1$ and (\ref{eq:xcount}) is precisely $\alpha_{i+1}$ which counts the number of vertices adjacent to $u$ and at distance $i$ from $v$. Also observe that $(A_{i-1})_{u,v} = 0$ in this case. So we have
$$e_u^T A_1 A_i e_v = c_i (A_{i-1})_{u,v} + b_i(A_{i+1})_{u.v}.$$
\paragraph{}
It remains to consider when $(\ref{eq:xcount}) = 0$. In this case $h(u,v) \neq i \pm 1$. If $h(u,v) = i + 1$ then let $x$ be the vertex immediately following $u$ on the $i+1$ length $u$-$v$ path. The $x$-$v$ subpath of $u$-$v$ path of length $i+1$ is of length $i$ so $h(x, v) \leq i$. If $h(x,v) < i$ then take the $x$-$v$ path of length $<i$ and join $u$ to the beginning of it giving a $u$-$v$ path of length $< i+1$, contradicting that $h(u,v) = i+1$. So $h(x,v) = i$. But this contradicts $(\ref{eq:xcount}) = 0$. So $h(u,v) \neq i+1$. Similarly suppose $h(u,v) = i-1$. Then $i-1<n$ and hence there exists an index $k$ for which $u_k = v_k$ (as $u,v$ differ in $i-1$ indices). Let $x = u \oplus e_k$. Then $x \in \delta(u)$ and $h(x,v) = h(u,v) + 1 = i.$ But this contradicts that (\ref{eq:xcount}) $=0$. So $h(u,v) = i \pm 1$. Thus $$(A_{i\pm1})_{u,v} = 0$$ and so
$$e_u^T A_1 A_i e_v = c_i (A_{i-1})_{u,v} + b_i(A_{i+1})_{u.v}.$$
\paragraph{}
Now since $u,v$ were arbitrary, and $c_i$ and $b_i$ are independent of $u$ and $v$ we have
$$A_1 A_i = c_i A_{i-1} + b_i A_{i+1}.$$ $\blacksquare$

\section{}
\paragraph{}
Consider the Hamming graph $H(n,2)$. Proceed by induction on $i$. For the sake of precision our claim to be proved by induction is
$$\text{ for any $i \in \{1, \dots, n\}$, $h(u,v) = i=d(u,v)$}$$
where $d(u,v)$ is the distance (length of shortest path) between $u$ and $v$ as vertices of $H(n,2)$, and $h(u,v)$ is the Hamming distance between $u$ and $v$.
\paragraph{}
In the base case, $i=1$ the result is immediate by definition of $H(n,2)$. Now let $i \in \{2,\dots, n\}$ and suppose the claim holds for any $j \in \{1, \dots, i-1\}$. Let $u,v \in \Z^n_2$ be two vertices of $H(n,2)$. Suppose $h(u,v) = i$. Then there exists $k$ such that $u_k \neq v_k$. Let $x = u \oplus e_k$. Then $h(x,v) = i-1$. By induction $d(x,v) = i-1$. Since $x \in \delta(u)$ we have $$d(u,v) \leq d(x,v) +1 = i.$$
Suppose for a contradiction that $d(u,v) < i$. Then by induction $h(u,v) < i$, a contradiction to $h(u,v) = i$. Hence $d(u,v) = i = h(u,v)$.
\paragraph{}
Therefore by induction $h(u,v) = d(u,v)$ for any $i \in \{1,\dots, n\}$. $\blacksquare$

\section{}
Let $J(v,k)$ be the graph whose vertices are $k$-subsets of $V = \{1,\dots,v\}$ where $k$-subsets $\alpha$ and $\beta$ are adjacent if and only if $|\alpha \cap \beta | = k-1$. Assume $2k \leq v$. We want to show that $$\text{$k$-subsets $\alpha$ and $\beta$ are at distance $i$ in $J(v,k)$ if and only if $|\alpha \cap \beta | = k-i$}.$$
Let $d(\alpha,\beta)$ denote the distance between $k$-subsets $\alpha$ and $\beta$. Let $j(\alpha, \beta) = k - |\alpha \cap \beta|$. Then equivalently we will show
$$\text{ $k$-subsets $\alpha$ and $\beta$ are such that $d(\alpha, \beta) = i = j(\alpha, \beta)$ for any $i \in \{1, \dots, k\}$}.$$
We proceed by induction on $i$. In the base case $i=1$ the claim holds by definition. Suppose that the claim holds for any $k$-subsets at distance less than $i$ for $i>1$. Let $\alpha, \beta$ be $k$-subsets such that $j(\alpha, \beta) = i > 1$.  Then 
$|\alpha \cap \beta| = k -i < k$
so there exists $a \in \alpha\backslash\beta$ and there exists $b \in \beta\backslash\alpha$.  Let $$\gamma = \beta \backslash \{b\} \cup \{a\}.$$
Then $|\gamma \cap \beta | = k-1$ and hence $\gamma \in \delta(\beta)$. Now we have
\begin{align*}
|\alpha \cap \gamma | &= | \alpha \cap (\beta \backslash \{b\} \cup \{a\})| \\
&= | \alpha \cap \beta \backslash\{b\} \cup \alpha \cap \{a\}| \\
&=|\alpha \cap \beta | + 1 \\
&= k - i + 1.
\end{align*}
So $j(\alpha, \gamma) = k - k + i -1 = i -1 < i$. Then by induction $d(\alpha, \gamma) = i-1$. Since $\gamma \in \delta(\beta)$ this give $d(\alpha, \beta) \leq i$. But if $d(\alpha,\beta) < i$ then by induction $j(\alpha, \beta) < i$, a contradiction, so we have in fact that $d(\alpha, \beta) = i$. Therefore by induction the claim holds for all $i$. $\blacksquare$
\section{}
\paragraph{}
We use the equivalence between distance in $J(v,k)$ and size of intersection as outlined and proven in problem $3$ throughout.
\paragraph{}
Let $A_i$ be the adjacency matrix of the $i$-distance graph of $J(v,k)$ and set $A_0 = I$. Let $\alpha, \beta$ be $k$-subsets of $V = \{1, \dots, v\}$. Then for any $b \in V \backslash \alpha$ and $a \in \alpha$ we have
$$|\alpha \cap (\alpha \backslash \{a\} \cup \{b\}| = k -1$$
and hence $(\alpha \backslash \{a\} \cup \{b\}) \in \delta(\alpha)$. In fact any $\gamma \in \delta(\alpha)$ has this form as there is precisely one element of $\alpha$ not in $\gamma$ and conversely there is precisely one element in $\gamma$ not in $\alpha$.
\paragraph{}
There are $v-k$ choices of $b$ and $k$ choices of $a$ and hence $|\delta(\alpha)| = (v-k)k$ for any $k$-subset $\alpha$. Thus $J(v,k)$ is regular. Let $i \{1,\dots, k-1\}$. Suppose $|\alpha \cap \beta| = k-i$. As before let $a \in \alpha$ and let $b \in V \backslash \alpha$. Let $\gamma = \alpha \backslash\{a\} \cup \{b\}$. Consider the cases
\begin{enumerate}
\item $a \in \beta$ and $b \in \beta$
\item $a \in \beta$ and $b \not\in \beta$
\item $a\not\in \beta$ and $b\in \beta$
\item $a\not\in \beta$ and $b \not\in \beta$.
\end{enumerate}
\paragraph{}
In cases $1$ and $4$ we have $|\beta \cap \gamma | = |\beta \cap \alpha| = k-i$. There are $(k-i)i + i(v-k-i)$ ways to choose $\alpha$ and $\beta$ this way. Set $a_i = (k-i)i + i(v-k-i)$. Then for any $k$-subsets vertices satisfying $|\alpha \cap \beta| = k-i$, $a_i$ counts the number of $k$-subsets adjacent to $\alpha$ and with intersection size $k-i$ with $\beta$.
\paragraph{}
In case $2$ we have $|\beta \cap \gamma | = |\beta \cap \alpha| -1$. There are $(k-i)(v-k-i)$ ways to choose $\alpha$ and $\beta$ this way. Set $c_{i-1} = (k-i)(v-k-i)$. Then for any $k$-subsets vertices satisfying $|\alpha \cap \beta| = k-i$, $c_{i-1}$ counts the number of $k$-subsets adjacent to $\alpha$ and with intersection size $k-i-1$ with $\beta$.
\paragraph{}
In case $3$ we have $|\beta \cap \gamma | = k-i +1$. There are $i^2$ ways to choose $\alpha$ and $\beta$ this way. Set $b_{i+1} = i^2$. Then for any $k$-subsets vertices satisfying $|\alpha \cap \beta| = k-i$, $b_{i+1}$ counts the number of $k$-subsets adjacent to $\alpha$ and with intersection size $k-i+1$ with $\beta$.
\paragraph{}
Let $\alpha$ and $\beta$ be $k$-subsets of $V$. Then as in problem $1$ $(A_1A_i)_{\alpha,\beta}$ counts the number of $k$-subsets $\gamma$ such that $\gamma \in \delta(\alpha)$ and $|\beta \cap \gamma| = k-i$. As $\alpha \in \delta(\gamma)$ we have that either
\begin{itemize}
\item $|\alpha \cap \beta| = k-i$ or
\item $|\alpha \cap \beta| = k-i-1$ or
\item $|\alpha \cap \beta| = k-i + 1$.
\end{itemize}
\paragraph{}
In the first case $a_i$ counts exactly how many such $\gamma$ there are. In this case $(A_i)_{\alpha,\beta} = 1$, and $(A_{i-1})_{\alpha,\beta} = (A_{i+1})_{\alpha,\beta} = 0$. So
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}.$$
\paragraph{}
In the second case $b_i$ counts exactly how many such $\gamma$ there are. In this case $(A_{i+1})_{\alpha,\beta} = 1$, and $(A_{i})_{\alpha,\beta} = (A_{i+1})_{\alpha,\beta} = 0$. So
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}.$$
\paragraph{}
In the third case $c_i$ counts exactly how many such $\gamma$ there are. In this case $(A_{i-1})_{\alpha,\beta} = 1$, and $(A_{i})_{\alpha,\beta} = (A_{i-1})_{\alpha,\beta} = 0$. So
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}.$$
\paragraph{}
It remains to consider when $(A_1A_i)_{\alpha,\beta} = 0$. If $|\alpha \cap \beta| = k-i$ then either there exist distinct $a, b \in \alpha \cap \beta$ and hence $\gamma = \alpha \backslash\{a\} \cup \{b\}  \in \delta(\alpha)$ and $|\beta \cap \gamma| = k-i$, or $\alpha \cap \beta = \{a\}$. In the first $\gamma$ cannot exist as $(A_1A_i)_{\alpha,\beta} = 0$, a contradiction. In the second $a_i = 0$ and so
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}$$
still holds.
\paragraph{}
Now suppose $(A_1A_i)_{\alpha,\beta} = 0$ and $|\alpha \cap \beta| = k-i -1$. If $\alpha \cap \beta \neq \emptyset$ then there is $a \in \alpha \cap \beta$ and $b \in \beta \backslash \alpha$. Let $\gamma = \alpha \backslash\{a\} \cup \{b\}$. Then $\gamma \in \delta(\alpha)$ and $|\beta \cap \gamma| = k-i$, contradicting $(A_1A_i)_{\alpha,\beta} = 0$, so this case cannot happen. If $\alpha \cap \beta = \emptyset$ then $c_i = 0$ and so
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}$$
still holds
\paragraph{}
Finally suppose $(A_1A_i)_{\alpha,\beta} = 0$ and $|\alpha \cap \beta| = k-i +1$. If $\alpha \cap \beta \neq \emptyset$ then there is $a \in \alpha \backslash \beta$ and $b \in \beta \cap \alpha$. Let $\gamma = \alpha \backslash\{a\} \cup \{b\}$. Then $\gamma \in \delta(\alpha)$ and $|\beta \cap \gamma| = k-i$, contradicting $(A_1A_i)_{\alpha,\beta} = 0$, so this case cannot happen. If $\alpha \cap \beta = \emptyset$ then $b_i = 0$ and so
$$(A_1A_i)_{\alpha,\beta} = c_i A_{i-1} + a_iA_i + b_iA_{i+1}$$
$\blacksquare$
\section{}
\paragraph{}
Let $K = J_2 - I_2$ be the adjacency matrix of $K_2$. We will prove the claim:
$$(I + tK)^{\otimes n} = A_0 + tA_1 + \dots + t^nA_n$$
where $A_i$ is the $i$-th distance matrix of $H(n,2)$ by induction, setting $A_0 = I$. In the base case $n=1$, $H(1,2)$ has two vertices, $0$ and $1$, both adjacent, so
$$A_1 = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = K.$$
Therefore
$$(I+tK)^{\otimes 1} = I + tK = A_0 + tA_1$$
as desired.
\paragraph{}
For induction let $n > 1$ and suppose the claim holds for Kronecker powers smaller than $n$. We have by induction
$$(I + tK)^{\otimes n} = (I+tK)(I+tK)^{\otimes n-1} = (I+tK)\otimes(\sum_{i=0}^{n-1} t^iB_i)$$
where $B_i$ is the $i$-th distance matrix of $H(n-1,2)$. Since $\otimes$ distributes over addition we have
$$(I+tK)\otimes(\sum_{i=0}^{n-1} t^iB_i) = \sum_{i=0}^{n-1} (I \otimes B_i)t^i + \sum_{i=0}^{n-1} (K \otimes B_i) t^{i+1} = I\otimes B_0 + \sum_{i=1}^{n-1}[(I \otimes B_i + K \otimes B_{i-1})t^i] + t^n K\otimes B_{n-1}$$
Thus we have three things to verify: that $$I \otimes B_0 = A_0,$$
$$(I \otimes B_i + K \otimes B_{i-1})t^i = A_i$$
for $i = 1, \dots, n-1$, and 
$$K \otimes B_{n-1} = A_n$$
where $A_i$ is the $i$-th distance matrix of $H(n,2)$.
\paragraph{}
To verify that $I \otimes B_0 = A_0$ we simply must check that the identity matrix given by $I \otimes B_0$ is of appropriate dimensions. Since $H(n-1,2)$ has $2^{n-1}$ vertices (count subsets of a set of $n-1$ elements), $B_0$ is of dimensions $2^{n-1} \times 2^{n-1}$. Also we know $I$ is $2\times 2$ so we that that the dimensions of $I \otimes B_0$ are
$2(2^{n-1}) \times 2(2^{n-1}) = 2^n \times 2^n$
as desired. Notice this argument actually demonstrates that the matrices whose properties which remain to verify are all of appropriate dimensions.
\paragraph{}
Let $v \in Z^n_2$ be a vertex  of $H(n,2)$ and let $u\in \Z^{n-1}_2$ be such that $u_i = v_i$ for $i = 1, \dots, n-1$. Then 
$$v = \begin{cases}\begin{bmatrix}u\\0\end{bmatrix} + 0, &\text{if $v_n = 0$} \\ \begin{bmatrix}u\\0\end{bmatrix} + e_n, &\text{if $v_n = 1$} \end{cases}$$
where $e_n$ is the $n$-th standard basis vector. That is, we may think of $v$ as being given by a vertex of $H(n-1,2)$ that is extended by either a $0$ or $1$ in the $n$-th coordinate. We will now describe $A_i$. We may assume without loss of generality that the rows and columns of the matrices $B_0, \dots, B_{n-1}$ are arranged indexing vertices $u^1, \dots, u^{2^{n-1}}$, and the rows and columns of $A_i$ are arranged indexing $$\begin{bmatrix}u^1 \\ 0 \end{bmatrix} , \dots, \begin{bmatrix}u^{2^{n-1}} \\ 0 \end{bmatrix}, \begin{bmatrix}u^1 \\ 1 \end{bmatrix}, \dots, \begin{bmatrix}u^{2^{n-1}} \\ 1 \end{bmatrix}.$$
Let $v, y \in \Z^n_2$ and let $u, x \in \Z^{n-1}_2$ be the vertices extended to obtain $v$ and $y$ respectively. If $v_n = y_n = 0$ or $v_n = y_n = 1$ then
$$h(v,y) = h(u,x).$$
So if $u,x$ are at distance $i$ in $H(n-1,2)$ then there extensions which have the same $n$-th coordinates are at distance $i$ in $H(n,2)$. Therefore the diagonal blocks of $A_i$ are $B_i$. Now if $v_n \neq y_n$ then
$$h(v,y) = h(u,x) + h(e_n, 0) = h(u,x) + 1.$$
So if $u,x$ are at distance $i-1$ in $H(n-1,2)$ then there extensions which have differing $n$-th coordinates are at distance $i$ in $H(n,2)$. Therefore the anti-diagonal blocks of $A_i$ are $B_{i-1}$. Collecting these observations we conclude that
$$A_i = \begin{bmatrix}B_i & B_{i-1} \\ B_{i-1} & B_i. \end{bmatrix}$$
but for $i = 1,\dots,n-1$ this is exactly $I \otimes B_i + K \otimes B_{i-1}$. 
\paragraph{}
Finally for $A_n$ the anti-diagonal blocks are still $B_{n-1}$ as argued previously but since there are no vertices in $H(n-1,2)$ at distance $n$ we have
$$A_n = \begin{bmatrix}0 & B_{n-1} \\ B_{n-1} & 0. \end{bmatrix}$$
which is exactly $K\otimes B_{n-1}$ as desired. So by induction the result holds. $\blacksquare$
\section{}
\paragraph{}
We have that the eigenvalues of $I+tK$ are $1+t$ and $1-t$. We claim that for any matrices $A, B$ the eigenvalues of $A \otimes B$ are
$$\lambda_i \mu_j \quad \text{for any $i =1,\dots, n$ and $j = 1,\dots,m$}$$ 
where $\lambda_1, \dots, \lambda_n$ are the eigenvalues of $A$ and $\mu_1, \dots, \mu_m$ are the eigenvalues of $B$. Indeed let $\lambda_i$ be an eigenvalue of $A$ with eigenvector $x$ and let $\mu_j$ be an eigenvalue of $B$ with eigenvector $y$. Then 
$$(A\otimes B)(x\otimes y) = (Ax \otimes By) = (\lambda_i x \otimes \mu_j y) = \lambda_i\mu_j(x\otimes y)$$
so $\lambda_i \mu_j$ is an eigenvalue of $A\otimes B$. There are $nm$ such $\lambda_i\mu_j$ and $A \otimes B$ is of order $nm \times nm$ so these such $\lambda_i \mu_j$ are all the eigenvalues of $A\otimes B$.
\paragraph{}
We will show that the eigenvalues of
$$(I + tK)^{\otimes n} = (1+t)^k(1-t)^{n-k} \quad\text{for $k = 0,\dots, n$}$$
by induction on $n$. In the base case $n=1$ we have already noted that the eigenvalues of $I+tK$ are $1 \pm t$. Now let $n > 1$ and suppose that the eigenvalues of $(I+tK)^{\otimes n-1}$ are $(1+t)^k(1-t)^{n-1-k}$ for any $k =0, \dots, n-1$. Since
$$(I + tK)^{\otimes n} = (I+tK) \otimes (I+tK)^{\otimes n-1},$$
by our claim we know that the eigenvalues of $(I+tK)^{\otimes n}$ are $\lambda_i \mu_j$ for $i = 1, \dots, 2$ and $j = 1,\dots, 2^{n-1}$ where $\lambda_i$ is an eigenvalue of $I+tK$ and $\mu_j$ is an eigenvalue of $(I+tK)^{\otimes n-1}$. Let $k \in \{ 0, \dots, n\}$. If $k >0$ then we observe that
$$(1+t)^k(1-t)^{n-k} = (1+t)(1+t)^{k-1}(1-t)^{n-1-k}$$
and since $1+t$ is an eigenvalue of $I+tK$ and $(1+t)^{k-1}(1-t)^{n-1-k}$ is an eigenvalue of $(I+tK)^{\otimes n-1}$ by induction, we have $(1+t)^k(1-t)^{n-k}$ is an eigenvalue of $(I+tK)^{\otimes n}$. Now if $k = 0$ then
$$(1+t)^k(1-t)^{n-k} = (1-t)^{n} = (1-t)(1-t)^{n-1}$$
and since $1-t$ is an eigenvalue of $I+tK$ and $(1-t)^{n-1}$ is an eigenvalue of $(I+tK)^{\otimes n-1}$ by induction, we have $(1+t)^k(1-t)^{n-k}$ is an eigenvalue of $(I+tK)^{\otimes n}$. Hence the result holds by induction.
\paragraph{}

\end{document}
