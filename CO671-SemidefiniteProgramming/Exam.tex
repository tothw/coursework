\documentclass[letterpaper,11pt,oneside,onecolumn]{article}
\usepackage[margin=0.5in, bottom=0.5in, top=0.75in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 Course Summmary} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{Foundations}
\subsection*{Positive Semidefinite Matrices}
\paragraph{Equivalent Definitions} The following are equivalent: $(a)$ Matrix $A$ is positive semidefinite ($A\succcurlyeq 0$), $(b)$ $A$ is a symmetric and for all $x$, $x^TAx \geq 0$, $(c)$ $A = B^TB$ for some $B$, $(d)$ all eigenvalues of $A$ are non-negative, $(e)$ $\langle A, X\rangle \geq
 0$ for all $X \succcurlyeq 0$.
 \paragraph{Notes} $\langle A, X\rangle = trace(A^TX)$. Non-singular positive-semidefinite matrices are called positive definite.
 \paragraph{Necessary Conditions}
 If $A \succcurlyeq 0$ and $rank(A) = r$ then $A$ can be written as the sum of $r$ rank $1$ PSD matrices. Also each principal submatrix of $A$ is PSD.
 \paragraph{Cholesky} $M = \begin{bmatrix} A & B \\  B^T &D\end{bmatrix} \succcurlyeq 0$ iff $A \succcurlyeq 0$ and $D - B^TA^{-1}B \succcurlyeq 0$ (note: $A$ is non-singular).
\paragraph{Kronecker Product} $(A \otimes B)_{(i,k),(j,\ell)} = A_{i,j}B_{k,\ell}$. Properties: $(A\otimes B)(C\otimes D) = AC \otimes BD$, $(A\otimes B)^T = A^T \otimes B^T$, $tr(A \otimes B)= tr(A) tr(B)$, $vec(AXB^T) = (A\otimes B)vec(X)$.
\paragraph{Schur Product} $(A \circ B)_{i,j} = A_{i,j}B_{i,j}$. Properties: $(A\otimes B) \circ(C\otimes D) = (A\circ C) \otimes (B \circ D)$ and $(A \circ B)\otimes(C\circ D) = (A\otimes C) \circ(B \otimes D)$, $\langle A, B \rangle = sum(A \circ B)$.
\paragraph{Products and PSD} If $A, B\succcurlyeq 0$ then $A\otimes B \succcurlyeq 0$. If $A$ and $B$ are of the same order then $A\circ B \succcurlyeq 0$.
\subsection*{Convex Sets}
\paragraph{Theorem} If $f$ is a continuous function on compact set $C$ then there exists $c\in C$ such that $f(x) \leq f(c)$ for all $x \in C$.
\paragraph{Affine space} Affine subspaces of a vector space are closed under affine combinations: $y = \sum_r a_r x_r$ with $\sum_r a_r =1$ means $y$ is an affine combination of $x_r$'s. If the maximum size of an affinely independent spanning set of $C$ is $d+1$ then $C$ has affine dimension $d$.
\paragraph{Convex space} Convex combinations are affine combinations where scalars $a_r \geq 0$. Convex spaces are those closed under convex combinations. Half-spaces are convex sets of the form $\{x \in V: \langle \alpha, x \rangle \leq b\}$. A compact convex set is the convex hull of its extreme points. If $x = sa + (1-s)b$ for $0\leq s \leq 1$, $a,b \in C$ implies $s=0$ or $s=1$ then $x$ is an extreme point of $C$. A convex hull of a set of point is the smallest convex set containing those points.
\paragraph{Hyperplanes and Separation}
A hyperplane $\langle h, x\rangle = c$ separates $A,B$ if for all $a \in A$, $\langle h, a\rangle \leq c$ and for all $b \in B$, $\langle h, b \rangle \geq c$. Hyperplane $H$ supports convex set $C$ at $y \in C$ if $C$ lies entirely in one half-space determined by $H$ and $y \in H \cap C$. The metric projection $\pi_C(x) :=$ point in $C$ nearest to $x \not\in C$ has the property that the hyperplane with normal $x - \pi_C(x)$ supports $C$ at $\pi_C(x)$.
\paragraph{Cones} A convex cone is a convex set closed under non-negative linear combinations. The set of PSD matrices of order $n$ form a cone. The dual of cone $K$, denoted $K^*$ is $K^*=\{v \in V: \langle v,k \rangle \geq 0 \text{ for all } k \in K \}$. The PSD cone is self-dual.
\section*{Semidefinite Programs}
\subsection*{Canonical Form}
\paragraph{Primal Conic Program} If $K$ is a closed convex cone then then problem:
$\sup \{\langle C, X \rangle : \langle A_i, X \rangle = b_i (i=1,\dots, m), X \in K \} $ is called our primal problem. If $K$ is the cone of PSD matrices then we have a Semidefinite Program.
\subsection*{Duality}
\paragraph{Dual Conic Program} Corresponding to the primal we have a dual problem given by $\inf \{ y^Tb : \sum_i y_iA_i - C \in K^*\}.$
\paragraph{Duality Theorems} (Weak:) If $y$ is dual feasible and $X$ is primal feasible then $y^Tb \geq \langle C, X\rangle$ with equality iff $\langle \sum_i y_i A_i - C, X\rangle = 0$. (Strong:) If there is $y$ s.t. $\sum_i y_i A_i - C \in int(K^*)$ and dual is bounded below then primal has an optimal solution with no duality gap (difference between primal/dual optimal solutions).
\paragraph{Farkas-Type Lemma} If $K$ is a pointed closed convex cone s.t $int(K) \neq \emptyset$, and system $\langle A_i, X \rangle = b_i (i=1,\dots,m)$ has a solution then exactly one of: (a) There is $X \in int (K)$ st. $\langle A_i, X\rangle = b_i$ for all i, (b) There is $y$ s.t. $\sum_i y_i A_i \in K^*\backslash \{0\}$ and $y^Tb \leq 0$ holds.
\subsection*{Algorithms}
\paragraph{Interior Point Method} Problems of the form $\max\{\langle C, X\rangle + \mu \log(\det(X)) : \langle A_i, X\rangle = b_i (i=1,\dots,m),\ X\succ 0 \}$ -$(1)$ can be solved using Newton's gradient descent method since the barrier function: $\mu \log\det(X)$ for $\mu > 0$ allows us to ignore the constraint $X \succ 0$, resulting in a standard problem of convex maximization over an affine space. Hence to solve a standard SDP, solve a corresponding sequence of problems $(1)$ with $\mu \rightarrow 0$ and the optimal solutions $X^*(\mu)$ will converge to the optimal solution of the SDP.
\section*{Applications}
\subsection*{Lovasz Theta}
\paragraph{Strong Product, Shannon Capacity, Lovasz Theta} For graphs $G, H$ the strong product $G \boxtimes H$ is the graph s.t. $V(G\boxtimes H) = V(G) \times V(H)$ and $(u,x)(v,y) \in E(G\boxtimes H)$ iff $u=v$ and $x \sim y$, or $u\sim v$ and $x=y$, or $u\sim v$ and $x\sim y$. The Shannon capcity of a graph is given by $\Theta(G) = \sup_k \alpha(G^{\boxtimes k})^\frac{1}{k}$ where $\alpha(G)$ is max stable set size of $G$. If $V(G) = \{1,\dots, n\}$ and $u_1, \dots, u_n$ are unit vectors s.t. $\langle u_i, u_j\rangle = 0$ if $i \sim j$ (orthogonal representation) then $\theta(G) = \min_{||c|| = 1} \max_{1\leq i \leq n} \frac{1}{\langle, c,u_i\rangle^2}$ is Lovasz's Theta. We have $\Theta(G) \leq \theta (G)$.
\paragraph{SDP for $\theta(G)$} For graph $G$ with $V(G) = \{1,\dots,n\}$ let $\Omega$ be set of $n\times N$ PSD matrices $N$ s.t. $tr(N) = 1$ and $N_{i,j} = 0$ if $i\sim j$. Then $\theta(G) = \max_{N \in \Omega} \langle J, N\rangle$.
\subsection*{Codes, Colouring, Packing}
\subsection*{Quantum Channels}
\section*{Copositive and Completely Positive Programming}
\end{document}
