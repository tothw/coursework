\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\DeclareMathOperator{\conv}{conv}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 A3} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{11}
\paragraph{}
Let $A, B$ be $n \times n$ symmetric matrices of rank $1$ such $A$ is not a scalar multiple of $B$. Since $A$ and $B$ are rank $1$ symmetric matrices there exists $a, b \in \R^n$ such that $$A = aa^T \quad \text{and}\quad B = bb^T.$$
We will show that $\{a,b\}$ is a basis for the column space of $A+B$ and thus $rk(A+B) = 2 > 1$ as desired.
\paragraph{}
First observe that $a$ and $b$ are linearly independent. To see this, suppose that there exists $t$ for which $a = tb$. Then we have that $$A = aa^T = t^2bb^T = t^2B.$$
Which contradicts that $A$ is not a scalar multiple of $B$.
\paragraph{}
Now to show that $span\{a,b\} = col(A+B)$. We claim that for any $\alpha a + \beta b \in span \{a,b\}$ there exists $x \in \R^n$ such that $\alpha = a^Tx$ and $\beta = b^Tx$. Consider the system
\begin{equation} \begin{bmatrix} a^T \\b^T\end{bmatrix} x = \begin{bmatrix}\alpha \\ \beta\end{bmatrix}. \label{sys:star}\end{equation}
If (\ref{sys:star}) has no solutions then $a$ and $b$ are collinear. This contradicts that $a$ and $b$ are linearly independent. Thus (\ref{sys:star}) has a solution, and hence the claim holds. Now using the claim we may obtain that $span\{a,b\} = col(A+B)$ as follows. Let $\alpha a + \beta b \in span\{a,b\}$. Then there exists $x \in \R^n$ such that $$\alpha a + \beta b = aa^Tx + bb^Tx + (A+B)x.$$
Therefore $\alpha a + \beta b \in col(A+B)$. So $span\{a,b\} \subseteq col(A+B)$. Now let $(A+B)x \in col(A+B)$. Then $$(A+B)x = (a^Tx)a + (b^Tx)b$$
and so $(A+B)x \in span\{a,b\}.$ Therefore $span\{a,b\} = col(A+B)$, so we may conclude that $\{a,b\}$ is a basis for $col(A+B)$ and hence $rk(A+B) > 1$. $\blacksquare$
\section*{12}
\paragraph{}
Let $A$ and $B$ be $n \times n$ positive semidefinite matrices. We aim to show that the Schur product
$A \circ B$ is positive semidefinite. We will proceed by a series of claims. The first claim will show that $A\circ B$ is a principle submatrix of $A \otimes B$. Then we will show that any principle submatrix of of a positive semidefinite matrix is positive semidefinite. From there, since we know by problem $6$ that $A \otimes B$ is positive semidefinite we can conclude that $A \circ B$ is positive semidefinite.
\paragraph{Claim 1}
We claim that $A \circ B$ is a principle submatrix of $A \otimes B$. Formally, there exists $I \subseteq \{1, \dots, n\}$ such that $(A\otimes B)_I = A\circ B$. As a matter of notation, for any matrix $M$ by $M_I$ we mean the submatrix of $M$ consisting of rows indexed by $I$ and columns indexed by $I$. Observe that, by definition:
\begin{align*}
(A \circ B)_{i,j} &= A_{i,j}B_{i,j} \\
&= (A \otimes B)_{n(i-1) + i, n(j-1) + j} \\
&= (A \otimes B)_{(n+1)i -n, (n+1)j - n}.
\end{align*}
Thus if we let $I = \{(n+1)i - n: i \in \{1, \dots, n\}\}$ then $$A\circ B = (A\otimes B)_{I,I}.$$ So $A \circ B$ is a principle submatrix of $A\otimes B$ and the claim holds.
\paragraph{Claim 2}
Now we claim that any principle submatrix of a positive semidefinite matrix is positive semidefinite. Let $M$ be an $n \times n$ positive semidefinite matrix. Let $I \subseteq \{1,\dots, n\}$. Since $M$ is positive semidefinite $M$ is a Gram matrix. Let $m_1, \dots, m_n$ be the vectors describing the Gram matrix $M$. That is to say,
$$M_{i,j} = \langle m_i,m_j\rangle.$$
Then we have that $M_I$ is a Gram matrix formed by vectors $m \in \{m_i : i \in I\}$. Since Gram matrices are positive semidefinite, $M_I$ is positive semidefinite and the claim holds.
\paragraph{Finishing the problem}
Thus we have by problem $6$ that $A \otimes B$ is positive semidefinite as $A$ and $B$ are positive semidefinite. Now by Claim $1$ $A \circ B$ is principle submatrix of $A\otimes B$, and since $A \otimes B$ is positive semidefinite by Claim $2$ $A \circ B$ is positive semidefinite as desired. $\blacksquare$
\section*{13}
\paragraph{}
Let $S$ be a subspace of a real vector space of dimension $d$. Let $\conv(S)$ denote the convex hull of $S$. Let $x \in \conv(S)$. Then $x$ is a convex combination of vectors in $S$. Let $k$ be the minimum natural number for which
$$\sum_{i=1}^k a_i x_i = x$$
where $\sum_{i=1}a_i = 1$, each $a_i \geq 0$, and each $x_i \in S$. Suppose for a contradiction that $k > d+1$. Then $k-1 >d$ and since the dimension of $S$ is $d$, the vectors
$$x_2 - x_1, \dots, x_k -x_1$$
are linearly dependent. Then there exists $\lambda_2, \dots, \lambda_k$ not all zero for which
$$0 = \sum_{i=2}^k \lambda_i (x_i-x_1) = \sum_{i=2}^k \lambda_i x_i - \sum_{i=2}\lambda_i x_1.$$
So if we let $\lambda_1 = -\sum_{i=2}^k\lambda_i$ then
$$ \sum_{i=1}^k \lambda_i x_i = 0 \quad\text{and}\quad \sum_{i=1}^k \lambda_i = 0.$$
Notice that $\sum_{i=1}^k \lambda_i = 0$ yet not all $\lambda_i$ are zero, so there exists $\lambda_i >0$. Now for any scalar $\alpha$ we have that
$$x = \sum_{i=1}^k a_i x_i + \alpha \sum_{i=1}^k \lambda_i x_i = \sum_{i=1}^k (a_i - \alpha\lambda_i)x_i.$$
In particular we may choose
$$\alpha = \min\{\frac{a_i}{\lambda_i} : \lambda_i >0\}.$$
Since there exists $\lambda_i >0$ this choice of $\alpha$ is well defined. Let $i$ denote the index of the minimizing $\lambda_i$. Furthermore for any $j \in \{1, \dots, k\}$ we have
\begin{align*}
a_j - \alpha \lambda_j &= a_j - \frac{a_I}{\lambda_i} \lambda_i \\
&\geq a_j - \frac{a_j}{\lambda_j}\lambda_j \\
&= 0.
\end{align*}
In particular $a_i - \alpha \lambda_i = 0$. Also observe that $$\sum_{j=1}^k (a_j - \alpha \lambda_j) = \sum_{j=1}^k a_j - \alpha \sum_{j=1}^k \lambda_j = 1.$$
Therefore $$x = \sum_{j=1}^{i-1} (a_j - \alpha \lambda_j)x_j + \sum_{j=i+1}^{k} (a_j - \alpha \lambda_j)x_j.$$
That is, $x$ is a convex combination of $x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_k$. So $x$ can be written as a convex combination of $k-1$ vectors and this contradicts the minimality of $k$. Thus $k \leq d+1$ as desired. $\blacksquare$
\section*{14}
Let $A$ and $B$ be convex sets. Let $A+B$ denote their Minkowski sum, defined by:
$$A+B = \{x+y : x\in A\text{ and } y\in B \}.$$
Let $z_1, \dots, z_n \in A+B$ and let $\alpha_1, \dots, \alpha_n$ be scalars such that each $\alpha_i \geq 0$ and $\sum_{i=1}^n \alpha_i = 1$. By the definition of $A+B$, for each $z_i$ there exists $x_i \in A$ and $y_i \in B$ such that $$z_i = x_i + y_i.$$
Since $A$ is convex observe that
\begin{equation}
\sum_{i=1}^n \alpha_i x_i \in A
\label{eq:convA}
\end{equation}
and similarly since $B$ is convex
\begin{equation}
\sum_{i=1}^n \alpha_i y_i \in B.
\label{eq:convB}
\end{equation}
Let $a = \sum_{i=1}^n \alpha_i x_i$ and let $b = \sum_{i=1}^n \alpha_i y_i$. By (\ref{eq:convA}) $a\in A$ and by (\ref{eq:convB}) $b \in B$. Now we have that
\begin{align*}
\sum_{i=1}^n \alpha_i z_i &= \sum_{i=1}^n \alpha_i(x_i + y_i) \\
&= \sum_{i=1}^n \alpha_i x_i + \sum_{i=1}^n \alpha_i y_i \\
&= a + b.
\end{align*}
Hence we may conclude that $\sum_{i=1}^n \alpha_i z_i \in A + B$, and therefore $A+B$ is convex. $\blacksquare$
\section*{15}
Let $f$ be a non-constant complex polynomial of degree $n$. Then there exists $z_1, \dots, z_n$ and $a \in \C$ such that we may write $f$ as:
$$f(z) = a\Pi_{i=1}^n(z-z_i).$$
Then the derivative of $f$, denoted $f'$, is
$$f'(z) = a\sum_{i=1}^n \Pi_{j\neq i} (z-z_j). $$
So the ratio $\frac{f'}{f}$ is given by:
$$ \frac{f'}{f}(z) = \frac{a\sum_{i=1}^n \Pi_{j\neq i} (z-z_j)}{a\Pi_{i=1}^n(z-z_i)} = \sum_{i=1}^n \frac{1}{z-z_i}.$$
Let $z_0$ be a root of $f'$. If $z_0$ is a root of $f$ then it is trivially contained in the convex hull of the roots of $f$. So we may assume that $z_0$ is not a root of $f$. That is, $f(z_0) \neq 0$. Therefore we have
$$ 0 = \frac{f'}{f}(z_0) = \sum_{i=1}^n\frac{1}{z_0-z_i}.$$
Multiplying each $i^\text{th}$ term by $1 = \overline{z_0-z_i}/\overline{z_0-z_i}$. we obtain
$$ 0 = \sum_{i=1}^n\frac{\overline{z_0 - z_i}}{|z_0-z_i|^2}.$$
Using the basic fact of complex variables that $\overline{z_0-z_i} = \overline{z_0}-\overline{z_i}$ we may rewrite this as
$$\sum_{i=1}^n \frac{\overline{z_i}}{|z_0-z_i|^2} = \sum_{i=1}^n\frac{\overline{z_0}}{|z_0-z_i|^2}.$$
Taking complex conjugates gives
$$\sum_{i=1}^n \frac{1}{|z_0-z_i|^2}z_i = (\sum_{i=1}^n \frac{1}{|z_0-z_i|^2}) z_0.$$
Therefore if we let $q = \sum_{i=1}^n \frac{1}{|z_0-z_i|^2}$ and let each $\alpha_i = \frac{1}{q|z_0-z_i|^2}$ then
$$ \sum_{i=1}^n \alpha_i z_i = z_0.$$
So $z_0$ is a linear combination of the zeros of $f$. To see this combination is in fact convex observe that each $\alpha_i \geq 0$ and that:
$$\sum_{i=1}^n \alpha_i = \frac{1}{q} \sum_{i=1}^n \frac{1}{|z_0 - z_i|^2} = \frac{1}{q}\cdot q = 1.$$
Hence $z_0$ is contained in the convex hull of the roots of $f$. $\blacksquare$
\end{document}
