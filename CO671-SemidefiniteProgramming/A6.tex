\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 Assignment 6 - Problem Set 2} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{1}
\paragraph{}
Let $K$ be a convex cone. Let $B$ be a compact base for $K$.  We will use a basic result in Analysis to show that $K$ is closed:
$$
\text{A set $C$ is closed $\iff$ every convergent sequence in $C$ converges to a point in $C$.}
$$
Let $(x)_n \subseteq K$ be a convergent sequence in $K$. Let $x$ be the limit point of $(x)_n$. Then for every $x_n$ there exists $b_n \in B$ and $\alpha_n > 0$ such that
$$x_n = \alpha_n b_n.$$
Thus we have a sequence $(b)_n \subseteq B$ corresponding to the sequence $(x)_n$. Since $B$ is compact this sequence $(b)_n$ has a convergent subsequence $$(b)_{n_i}$$ that converges to $b \in B$.
Since $(x)_n$ converges, the subsequence $$(x)_{n_i}$$ corresponding to $(b)_{n_i}$ converges and its limit is also $x$. We also have a sequence of $(\alpha)_{n_i}$ satisfying
$$x_{n_i} = \alpha_{n_i} b_{n_i}$$
for all $n_i$.
Taking norms and dividing by $||b_{n_i}||$ we obtain
$$\alpha_{n_i} = \frac{||x_{n_i}||}{||b_{n_i}||}.$$
Since each $b_{n_i}$ is not $0$ this is well-defined. The norm $||\cdot||$ is a continuous map, so since $(x)_{n_i}$ and $(b)_{n_i}$ are convergent, the sequences of norms
$$||x_{n_i}|| \quad \text{and}\quad ||b_{n_i}||$$
are convergent. Then $(\alpha)_{n_i}$ is the quotient of two convergent sequences and this therefore continuous. Further since $b \in B$, $b \neq 0 $ and thus the limit of $\alpha_{n_i}$ is just the limit of quotients:
$$\lim_{n_i \rightarrow \infty} \alpha_{n_i} = \lim_{n_i \rightarrow \infty} \frac{||x_{n_i}||}{||b_{n_i}||} = \frac{||x||}{||b||}.$$
Let $\alpha$ denote $\frac{||x||}{||b||}$. Then $(\alpha)_{n_i}$ is convergent and converges to $\alpha$. Further $\alpha \geq 0$.
\paragraph{}
But now we have that
$$x_{n_i} = \alpha_{n_i} b_{n_i}.$$
That is, $x_{n_i}$ is the product of two convergent sequences and hence converges to the product of their limits. Thus
$$\lim_{n_i \rightarrow \infty} x_{n_i} = \lim_{n_i \rightarrow \infty} \alpha_{n_i} b_{n_i} =\alpha b.$$
Since $\alpha \geq 0$ and $b \in K$, $\alpha b \in K$. Therefore the subsequence $(x)_{n_i}$ of $(x)_n$ converges to a point in $K$. Since convergent sequences and their convergent subsequences has the same limit, $(x)_n$ converges to a point in $K$. Therefore $K$ is closed. $\blacksquare$
\section*{2}
\subsection*{Part 1}
\paragraph{}
Let $K$ be a pointed convex cone. Let $H$ be an affine hyperplane that does not contain $0$. Let this affine hyperplane we describe by all $x$ satisfing:
$$\langle h, x \rangle = c $$ where $c \neq 0$. Suppose that $H\cap K$ is bounded and $H \cap K \neq 0$. Let $k \in K$ such that $k \neq 0$. Let $R$ be the ray in $K$ formed by nonegative scalar multiples of $k$. Then either $R$ intersects $H$ at a unique point $b$ or $R$ is parallel to $H$ (possibly with infinite intersections or none).
\paragraph{}
Suppose for a contradiction that $R$ is parallel to $H$. Then, as $k \in R$,
$$\langle h, k \rangle = 0.$$
Let $a \in H \cap K$. Then for all $\alpha \geq 0$, $a + \alpha k \in H \cap K$. We can see this by observing that $a$ and $\alpha k$ are in $K$ and $K$ is closed under addition, and observing that
$$\langle h, a + \alpha k \rangle = \langle h, a \rangle + \alpha \langle h, k \rangle = \langle h, a \rangle + 0 = c.$$
But by appropriating choosing $\alpha$ we can make $|| a+ \alpha k||$ arbitrarily large. This contradictions that $H\cap K$ is bounded. Hence $R$ is not parallel to $H$.
\paragraph{}
So $R$ interesects $H$ at some unique point $b$. Since $b \in R$ we have that $b \in H \cap K$. Since $k \in R \backslash\{0\}$ and $b \in R \backslash \{0\}$ (as $0\not\in H$) there exists $\alpha > 0$ such that $$k = \alpha b.$$
Such choice of $\alpha$ is unique. Therefore for any $k \in K \backslash\{0\}$ there is a unique point $b$ in $H \cap K$, and a unique scalar $\alpha > 0$ such that $k = \alpha b$. That is, $H \cap K$ is a base for $K$. $\blacksquare$
\subsection*{Part 2}
\paragraph{}
We will us Part $1$ to show that positive semidefinite matrices of trace $1$ form a base for the cone of positive semidefinite matrices. But by Part $1$ it is enough to show that set of trace $1$ matrices form an affine hyperplance and that the set of positive semidefinite trace $1$ matrices is bounded.
\paragraph{}
Let $J$ be the all ones matrice. Then $$J = \begin{bmatrix}
1 \\
\vdots \\
1
\end{bmatrix}\begin{bmatrix}
1& \hdots & 1
\end{bmatrix}^T.
$$
Consider the affine hyperplane $H$ given by the set of $X$ satisfying
$$\langle I, X \rangle = 1$$
where $I$ is the identity matrix.
We claim that $H$ is exactly the set of trace $1$ matrices. Indeed
\begin{align*}
\langle I , X \rangle = 1 &\iff tr(I^TX) = 1 \\
&\iff tr(X) = 1.
\end{align*} 
Therefore the set of trace $1$ matrices is an affine hyperplane.
\paragraph{}
It remains to show that the set of trace $1$ positive semidefinite matrices in bounded. Let $X\succcurlyeq 0$ and suppose that $tr(X) = 1$. Let $r$ be the rank of $X$. Since $X \succcurlyeq 0$ there exists vectors $x_1, \dots, x_r$ such that
$$ X = \sum_{i=1}^r x_ix_i^T.$$
Let for each $i = 1,\dots,r$ let $\hat{x}_i$ be given by
$$ \hat{x}_i = \frac{x_i}{||x_i||}.$$
Then $$X = \sum_{i=1}^r ||x_i||^2 \hat{x}_i\hat{x}_i^T.$$
So taking the trace gives
\begin{align*}
1 &= tr(X) \\
&= \sum_{i=1}^r ||x_i||^2 tr(\hat{x}_i \hat{x}_i^T) \\
&= \sum_{i=1}^r ||x_i||^2 \hat{x}_i^T \hat{x}_i \\
&= \sum_{i=1}^r ||x_i||^2 ||\hat{x}_i||^2 \\
&= \sum_{i=1}^r ||x_i||^2.
\end{align*}
Now using this equality we show that $||X|| \leq 1$:
\begin{align*}
||X|| &= ||\sum_{i=1}^r ||x_i||^2 \hat{x}_i\hat{x}_i^T|| \\
&\leq \sum_{i=1}^r ||x_i||^2 ||\hat{x}_i\hat{x}_i^T|| \\
&= \sum_{i=1}^r ||x_i||^2 \langle \hat{x}_i \hat{x}_i^T, \hat{x}_i \hat{x}_i^T\rangle^{\frac{1}{2}} \\
&= \sum_{i=1}^r ||x_i||^2 tr(\hat{x}_i \hat{x}_i^T\hat{x}_i \hat{x}_i^T)^{\frac{1}{2}} \\
&= \sum_{i=1}^r ||x_i||^2 tr(\hat{x}_i \hat{x}_i^T)^\frac{1}{2} \\
&= \sum_{i=1}^r ||x_i||^2 (\hat{x}_i^T\hat{x}_i) ^\frac{1}{2} \\
&= \sum_{i=1}^r ||x_i||^2 \\
&= 1.
\end{align*}
Thus all positive semidefinite matrices of trace $1$ have norm at most $1$, and so the intersection of the hyperplane of trace $1$ matrices with the cone of positive semidefinite matrices is bounded. Therefore by Part 1 the set of trace $1$ positive semidefinite matrices is a base for the cone of positive semidefinite matrices. $\blacksquare$
\section*{3}

\section*{4}

\section*{5}
\paragraph{}
Let $x \in \R^d$ and $t\in \R$. We will show
$$\begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \succcurlyeq 0 \iff ||x|| \leq t.$$
\paragraph{Case 1}
We first consider the case where $t = 0$. Then the matrix $$\begin{bmatrix}0 & x \\ x^T & 0 \end{bmatrix} \succcurlyeq 0$$ if and only if for all $\begin{bmatrix} \bar{y} \\y \end{bmatrix} \in \R^d \times \R$ we have
$$\begin{bmatrix}\bar{y}^T & y \end{bmatrix} \begin{bmatrix}0 & x \\ x^T & 0 \end{bmatrix} \begin{bmatrix} \bar{y} \\y \end{bmatrix} \geq 0$$
which holds if and only if
$$2y\bar{y}^Tx \geq 0.$$
Thus if $$\begin{bmatrix}0 & x \\ x^T & 0 \end{bmatrix} \succcurlyeq 0$$ choose $\bar{y} = x$ and $y = 1$ and we have
$$2y\bar{y}^Tx  = 2||x||^2 \geq 0.$$
Also if $||x|| \leq t = 0$ then $x = 0$ and thus
$$2y\bar{y}^Tx = 0  \geq 0$$
for any $\bar{y}, y$. Therefore the result holds in this case.
\paragraph{Case 2}
Now we may assume that $t\neq 0$. In this case $tI$ is nonsingular and so we may use Theorem $2.4.1$ (Cholesky) of the course notes:
$$\begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \succcurlyeq 0 \iff tI \succcurlyeq 0 \quad \text{and}\quad t - x^T(tI)^{-1}x  = t - \frac{1}{t}x^Tx \succcurlyeq 0.$$
But $tI \succcurlyeq 0$ if and only if
$$ t\geq 0,$$
and hence 
$$t - \frac{1}{t}x^Tx \succcurlyeq 0 $$
if and only if $$t^2 \geq x^Tx.$$
But $t^2 \geq x^Tx$ simply states $t^2 \geq ||x||^2$ and thus taking square roots this holds if and only if
$$t \geq ||x||.$$
Therefore the result holds in both cases. $\blacksquare$
\section*{6}
\paragraph{}
Let $x\in \R^d$ and $t\in \R$. Then
$$\begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \succcurlyeq 0$$ if and only if for all $\begin{bmatrix} \bar{y} \\y \end{bmatrix} \in \R^d \times \R$ we have
$$\begin{bmatrix}\bar{y}^T & y \end{bmatrix} \begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \begin{bmatrix} \bar{y} \\y \end{bmatrix} \geq 0.$$
Multiplying out we have
$$ty^2 + 2\bar{y}^Txy + t||\bar{y}||^2.$$
If $t = 0$ then we are back in problem $5$ case $1$. Thus we may assume $t\neq 0$. In this case we complete the square:
$$ty^2 + 2\bar{y}^Txy + t||\bar{y}||^2 + \frac{(\bar{y}^Tx)^2}{t}-\frac{(\bar{y}^Tx)^2}{t}.$$
Which simplies giving $\begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \succcurlyeq 0$ if and only if
\begin{equation}t(y+\frac{\bar{y}^Tx}{t})^2 + t||\bar{y}||^2 - \frac{(\bar{y}^Tx)^2}{t} \geq 0\label{eq:quadratic}\end{equation}
for all $\begin{bmatrix} \bar{y} \\y \end{bmatrix} \in \R^d \times \R$.
\paragraph{}
Thus if $\begin{bmatrix}tI & x \\ x^T & t \end{bmatrix} \succcurlyeq 0$ then choosing $y =1$ and $\bar{y} = 0$ and substituting into (\ref{eq:quadratic}) we obtain:
$$t(1 + 0)^2 + 0 \geq 0$$
and thus $t \geq 0$. Now choosing $\bar{y} = x$ and $y = -\frac{\bar{y}^Tx}{t}$ and substituting into (\ref{eq:quadratic}) we obtain:
$$0 + t||x||^2 - \frac{(x^Tx)^2}{t} \geq 0$$
Since $x^Tx = ||x||^2$ and $t\geq 0$ we may rearrange giving
$$t^2||x||^2 \geq ||x||^4.$$
If $x = 0$ then since $t \geq 0$ we would have $||x|| \leq t$ as desired. Hence we may assume $x \neq 0$. Thus we may divide by $||x||^2$ obtaining
$$t^2 \geq ||x||^2$$
and thus taking square roots gives
$$t \geq ||x||$$ as desired.
\paragraph{}
Now if $||x|| \leq t$ then $t \geq 0$ (more precisely $t > 0$). Let $\bar{y} \in \R^d$ and $y \in \R$. Then $$t(y++\frac{\bar{y}^Tx}{t})^2 \geq 0$$
as it is the product of two non-negative quantities. Thus by (\ref{eq:quadratic}) it remains to show that
$$t||\bar{y}||^2 - \frac{(\bar{y}^Tx)^2}{t} \geq 0.$$
Indeed we have
\begin{align*}
t||\bar{y}||^2 - \frac{(\bar{y}^Tx)^2}{t} &= \frac{t^2||\bar{y}||^2 - (\bar{y}^Tx)^2}{t} \\
&\geq \frac{||x||^2||\bar{y}||^2 - (\bar{y}^Tx)^2}{t}  &\text{since $t \geq ||x||$}\\
&\geq \frac{(\bar{y}^Tx)^2 - (\bar{y}^Tx)^2}{t} &\text{by Cauchy-Schwarz} \\
&= 0.
\end{align*}
Therefore by (\ref{eq:quadratic}) the result holds. $\blacksquare$
\end{document}
