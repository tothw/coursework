\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 Assignment 5 - Problem Set 1} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{26}
\paragraph{}
To solve this problem we will first need that the interior of the cone of positive semidefinite matrices is the set of positive definite matrices, and to prove that we will first need a slightly different but equivalent view of points in the interior of convex sets.
\paragraph{Lemma 26.1}
Let $V$ be a vector space with norm $|| \cdot ||$, and let $C$ be a convex set contained in $V$. Let $x \in C$. Then $x \in \text{int}(C)$ if and only if for all $v \in V$ there exists $\epsilon >0$ such that $x + \epsilon v \in C$.
\paragraph{Proof of Lemma 26.1}
First suppose that $x \in \text{int}(C)$. Then there exists $\delta > 0$ such that for all $y$ satisfying $$|| x - y|| < \delta$$ we have that $y \in C$. Now let $v \in V$. If $v = 0$ then choose $\epsilon = 1$ and $x + \epsilon v = x + 0 = x$ and we are done. So we may assume $|| v|| > 0$.  Choose $\epsilon = \frac{\delta}{2 ||v||}$. We will show $$x + \epsilon v \in C$$. Indeed we have $$|| x - (x+\epsilon v)|| = || \frac{-\delta}{2||v||} v|| = \frac{\delta}{2}\frac{||v||}{||v||} = \frac{\delta}{2} < \delta.$$
Therefore $x +\epsilon v$ lies in the $\delta$ ball about $x$ and hence $x+\epsilon v \in C$ as desired.
\paragraph{}
Now for the contrapositive suppose that $x \not\in \text{int}(C)$. Then $x \in \delta(C)$, the boundary of $C$. By Lemma $3.4.3$ of the course notes there exists $y \not\in C$ such that $x = \pi_C(y)$. Let $v = y - x$. Then for all $\epsilon > 0$, $x + \epsilon v$ lies on the half-line from $x$ through $y$, and $x + \epsilon v \neq x$. We claim that since $x =\pi_C(y)$ and $y \not \in C$, the half-line from $x$ through $y$ intersects $C$ exactly at the point $x$, and hence for all $\epsilon > 0$, $x+ \epsilon v \not \in C$. So if we verify the claim we are done. We do so in the following paragraphs.
\paragraph{}
First suppose for contradiction there exists $\epsilon \geq 1$ such that $x + \epsilon v \in C$. Then $y$ lies on the line segment from $x$ to $x + \epsilon v$. Since $x \in C$ and $x +\epsilon v \in C$ this would imply $y \in C$ by the convexity of $C$. But $y \not\in C$, a contradiction.
\paragraph{}
Now suppose for contradiction that there exists $\epsilon \in (0,1)$ such that $x + \epsilon v \in C$. Then we have that
$$ ||y - (x + \epsilon v)|| = ||y - x - \epsilon y + \epsilon x|| = (1-\epsilon) ||y-x||.$$
Since $1-\epsilon > 0$ this implies
$$||y - (x + \epsilon v)|| < ||y -x|| $$
which contradicts that $\pi_C(y) = x$. So the claim holds. $\blacksquare$
\paragraph{Lemma 26.2}
Let $V$ be the vector space of symmetric $n\times n$ matrices. Let $K\subseteq V$ be the convex cone of positive semidefinite matrices. Then $$\text{int}(K) =\{A \in K : A\text{ is nonsingular}\}.$$
\paragraph{Proof of Lemma 26.2}
Let $A \in \text{int}(K)$. Suppose for a contradiction that $\text{null}(A) \neq \{0\}$. Let $x \neq 0 \in \text{null}(A)$. Then $-xx^T$ is a symmetric matrix of order $n$. So by Lemma $26.1$ there exists $\epsilon > 0$ such that $$A - \epsilon xx^T \in K$$. That is,
$$x^T(A - \epsilon xx^T)x \geq 0.$$
But we have
\begin{align*}
x^T(A - \epsilon xx^T)x &= x^TAx - \epsilon (x^Tx)^2  \\
&= -\epsilon (x^Tx)^2  &\text{Since $x\in\text{null}(A)$} \\
&< 0 &\text{Since $\epsilon > 0$ and, as $x \neq 0$, $(x^Tx)^2 > 0$}. 
\end{align*}
Hence $x^T(A - \epsilon xx^T)x \geq 0$ and $x^T(A - \epsilon xx^T)x  < 0$, a contradiction. Thus $\text{null}(A) = \{0\}$ and thus $A$ is nonsingular. Therefore $\text{int}(K) \subseteq \{A \in K : A \text{ is nonsingular}\}$.
\paragraph{}
Now let $A$ be positive definite. Let $B \in V$. Let
$$ \beta = \min_{\{x : ||x|| = 1\}} x^T B x.$$
As we have argued in problem $1$, $\{x : ||x||=1\}$ is compact. Further the function we are minimizing is continuous, so this choice of $\beta$ is well-defined. If $\beta \geq 0$ then $B$ is positive semi-definite. Choose $\epsilon = 1$ and we have
$$A + \epsilon B = A + B$$
is positive semidefinite by problem $4$. That is $A +\epsilon B \in K$.
\paragraph{}
So we may assume $\beta < 0$.  Let
$$ \gamma = \min_{\{x: ||x|| = 1\}} x^TAx .$$
Again, this choice of $\gamma$ is well-defined. Since $A$ is positive definite $\gamma > 0$.
Choose $$\epsilon = \frac{-\gamma}{\beta}.$$ Since $\gamma > 0$ and $\beta < 0$ we have $\epsilon > 0$. Let $x \in \R^n$. If $x^TBx = 0$ then
$$x^T(A+\epsilon B) x = x^TAx + 0 > 0$$ and thus $A + \epsilon B$ is positive semidefinite. Otherwise we have
\begin{align*}
x^T(A + \epsilon B) x &= x^TAx + \epsilon x^T B x \\
&= x^TAx + \frac{\gamma}{\beta} x^T B x \\
&\geq x^TAx + \frac{-x^TAx}{x^TBx} x^TBx  \\
&= 0
\end{align*}
and still $A + \epsilon B$ is positive semidefinite. Therefore by Lemma $26.1$, $A \in \text{int}(K)$ and thus $\text{int}(K) = \{A \in K : A \text{ is nonsingular}\}$ as desired. $\blacksquare$
\paragraph{Proof that $K$ is homogenous}
We need to show that for any two positive semidefinite matrices $A$ and $B$ in the interior of $K$ there exists a linear bijection from $K$ to $K$ (that is, automorphism) mapping $A$ to $B$. Let $A, B \in \text{int}(K)$. Then by Lemma $26.2$, $A$ and $B$ are positive definite. Therefore there exist nonsingular matrices $M$ and $N$ such that
$$ A = MM^T \quad B = NN^T.$$
Consider the map $f: K \rightarrow K$ defined by
$$f(C) = (NM^{-1})C(NM^{-1})^T.$$
\paragraph{}
First let us confirm that $f$ maps $A$ to $B$. We have
\begin{align*}
f(A) &= (NM^{-1})A(NM^{-1})^T \\
&= NM^{-1} MM^T(NM^{-1})^T \\
&=NM^{-1}MM^T(M^T)^{-1} N^T \\
&= N I I N^T \\
&= NN^T \\
&= B.
\end{align*}
\paragraph{}
We will now show that $f$ is a bijection (and that $f$ indeed maps $K$ to $K$). It is well known from Linear Algebra that left or right multiplication by a non-singular matrix is a bijective map. Since $f$ is simply a composition of such maps $f$ is also bijective. To see that $f$ maps $K$ to $K$ let $C \in K$. Since $C$ is positive semidefinite there exists $D$ such that$$C = DD^T.$$ Then 
\begin{align*}
f(C) &= (NM^{-1})C(NM^{-1})^T \\
&= (NM^{-1})DD^T(NM^{-1})^T  \\
&= (NM^{-1}D)(NM^{-1}D)^T.
\end{align*}
So $f(C) = EE^T$ where $E = NM^{-1}D$ and thus $f(C)$ is positive semidefinite, that is to say $f(C) \in K$.
\paragraph{}
Lastly we will show that $f$ is linear. Let $C, D \in K$ and let $\alpha, \beta$ be scalars. Then
\begin{align*}
f(\alpha C + \beta D) &= (NM^{-1})(\alpha C + \beta D)(NM^{-1})^T \\
&= \alpha (NM^{-1}) C (NM^{-1})^T + \beta (NM^{-1})D(NM^{-1})^T \\
&= \alpha f(C) + \beta f(D).
\end{align*}
Thus $f$ is a linear map and so we have shown that $f$ is an automorphism with $f(A) = B$. Therefore $K$ is homogenous. $\blacksquare$
\section*{27}
\paragraph{Lemma 27.1}
If a set $C$ is closed then for every convergent sequence of points in $C$ converges to a point in $C$.
\paragraph{Proof of Lemma 27.1}
Let $C$ be a closed set. Let $\bar{C}$ denote the complemenet of $C$. Since $C$ is closed, $\bar{C}$ is open. Suppose for a contradiction that there exists a converegent sequence $(a)_n \subseteq C$ that converges to $a \in \bar{C}$. We will contradict that $\bar{C}$ is open. Let $\epsilon > 0$. Then there exists $N \in \N$ such that for all $n \geq N$, $$||a_n - a|| < \epsilon.$$
Since any $a_n$ with $n \geq N$ is such that $a_n \in C$ we have that the $\epsilon$ ball about $a$ is not strictly contained in $\bar{C}$. That is there does not exist $\epsilon > 0$ for which the $\epsilon$ ball about $a$ is contained in $\bar{C}$. This contradicts that $\bar{C}$ is open. $\blacksquare$
\paragraph{Problem Solution}
Let $d \geq 2$. Let $P$ be the set of polynomials of degree less than $d$. Let $p,q \in P$. Declare that $p \geq q$ is $p-q = 0$ or the coefficient of the leading term of $p-q$ is positive. To show this order arises from convex cone we must show that $$K = \{p \in P : p=0 \text{ or the coefficient of the leading term of $p$ is positive}\}$$
is a convex cone.
\paragraph{}
It is enough to show that $K$ is closed under nonnegative scaling and addition. Let $p \in K$ and let $\alpha \geq 0$. If $p = 0$ then $\alpha p = 0$ and thus $\alpha p \in K$. Similarly if $\alpha = 0$ then $\alpha p = 0$ and thus $\alpha p \in K$. Otherwise, that is if the leading coefficient of $p$ is positive and $\alpha > 0$ then the leading coefficient of $\alpha p$ is $\alpha$ times the leading coefficient of $p$ which is positive. As the product of two positive numbers is positive the leading coefficient of $\alpha p$ is positive and thus $\alpha p \in K$.
\paragraph{}
Now we will show $K$ is closed under addition. Let $p, q \in K$. We may write $p$ and $q$ as
$$p = \sum_{i=0}^{d-1}p_i x^i \quad q = \sum_{i=0}^{d-1} q_i x^i.$$
If either $p=0$ or $q=0$ then $p+q=q$ or $p+q = p$ respectively and hence $p+q \in K$. So suppose neither $p$ nor $q$ are $0$. That is their leading coefficients are positive. Let $k$ be such that $p_k$ is the leading coefficient of $p$. Let $j$ be such that $q_j$ is the leading coefficient of $q$. We may assume without loss of generality that $k \geq j$ (otherwise switch roles of $p$ and $q$). Then we have that $q_k \geq 0$ as $q_k=q_j$ or $q_k = 0$. Thus the leading coefficient of $p+q$ is $$p_k + q_k \geq p_k + 0 > 0.$$
Hence the leading coefficient of $p+q$ is positive and thus $p+q \in K$. Therefore $K$ is closed under addition and we may conclude that $K$ is a convex cone.
\paragraph{}
Now we will show that $K$ is not closed via the contrapositive of Lemma $27.1$. Consider the sequence $(a)_n \subseteq K$ where each $a_i$ is given by
$$\frac{1}{i}x - 1.$$
Since $d \geq 2$ each $a_i \in K$ has the coefficient of the leading term being positive and its degree (which is $1$) is less than $d$. But it is easy to see that
$$ \lim_{n \rightarrow \infty} a_n = 0x -1 = -1.$$
That is, this sequence converges to $-1$ which is not in $K$. Thus we have a convergent sequence in $K$ which converges to a point not in $K$. Therefore by Lemma $27.1$, $K$ is not closed. $\blacksquare$
\section*{29}
\paragraph{}
Let $A$ be an $n \times n$ symmetric matrix. Consider the two optimization problems:
\begin{align}
\max\ &x^TAx \nonumber \\
\ni\ &||x|| = 1\label{p:U}\\
 &x \in \R^n\nonumber
\end{align}
and
\begin{align}
\max\ &\langle A, X \rangle \nonumber\\
\ni\ &tr(X) = 1 \label{p:S} \\
&X \succcurlyeq 0. \nonumber
\end{align}
\paragraph{}
We begin by showing value of (\ref{p:U}) $\leq$ value of (\ref{p:S}). Let $x \in \R^n$ be an optimal solution of (\ref{p:U}). Let $X = xx^T$. The $X \succcurlyeq 0$ and $$tr(X) = tr(x^Tx) = x^Tx = ||x||^2 = 1.$$
So $X$ is feasible for (\ref{p:S}). Thus we have
\begin{align*}
\text{value of (\ref{p:S})} &\geq \langle A, X \rangle \\
&= tr(Axx^T)  \\
&= tr(x^TAx) \\
&= x^TAx \\
&= \text{value of (\ref{p:U})}.
\end{align*}
\paragraph{}
It remains to show that value of (\ref{p:S}) $\leq$ value of (\ref{p:U}). Let $X$ be an optimal solution to (\ref{p:S}). Let $r$ be the rank of of $X$. Since $X\succcurlyeq 0$ there exist $x_1, \dots, x_r$ such that
$$X = \sum_{i=1}^r x_i x_i^T.$$
Let $$\alpha_i = ||x_i||^2 = x_i^Tx_i$$
and let $$\hat{x}_i = \frac{x_i}{||x_i||}.$$
Then we have that
$$X = \sum_{i=1}^r \alpha_i \hat{x}_i\hat{x}_i^T.$$
Now we observe that
\begin{align*}
1 &= tr(x) \\
&= tr(\sum_{i=1}^r x_i x_i^T) \\
&=\sum_{i=1}^r tr(x_i x_i^T) \\
&= \sum_{i=1}^r x_i^T x_i \\
&= \sum_{i=1}^r \alpha_i.
\end{align*}
That is,
$$\sum_{i=1}^r \alpha_i = 1.$$
Now let $x \in \R^n$ be an optimal solution to $(\ref{p:U})$. Then we have
\begin{align*}
\text{value of (\ref{p:S})} &= \langle A,X \rangle \\
&= tr(A\sum_{i=1}^n \alpha_i \hat{x}_i\hat{x}_i^T) \\
&= \sum_{i=1}^r \alpha_i tr(A\hat{x}_i\hat{x}_i^T) \\
&= \sum_{i=1}^r \alpha_i \hat{x}_i^TA\hat{x}_i \\
&\leq \sum_{i=1}^r \alpha_i x^TAx &\text{(by optimality of $x$ as each $\hat{x}_i$ are unit vectors)} \\
&= x^TAx &\text{(as $\sum_{i=1}^r \alpha_i = 1$)} \\
&= \text{value of (\ref{p:U})}.
\end{align*}
Therefore we have value of (\ref{p:S}) $\leq$ value of (\ref{p:U}), and value of (\ref{p:S}) $\geq$ value of (\ref{p:U}). Thus value of (\ref{p:S}) $=$ value of (\ref{p:U}) as desired. $\blacksquare$
\end{document}
