\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{bbm}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
\newcommand{\1}{\mathbbm{1}} 

\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\rhead{William Justin Toth 671 Assignment 10 - Problem Set 3} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{7}
\paragraph{}
Let $K(n,k)$ be the Kneser graph. We define a homomorphism, $h$ from $K(n,k)$ to $S(n, \frac{-1}{\frac{n}{k}-1}) = S(n, \frac{-k}{n-k})$ as follows: Let $A \in V(K(n,k))$ and let $\chi(A)$ denote the characteristic vector of $A$. That is $\chi(A) \in \R^n$ with $\chi(A)_i = 1$ if $i \in A$ for $i =1,\dots, n$ and $\chi(A)_i = 0$ otherwise. Define
$$h(A) = \frac{1}{\sqrt{k}\sqrt{1 - \frac{k}{n}}} (\chi(A) - \frac{k}{n} \1)$$
where $\1$ is taken to be the all ones vector of size $n$ in this context. We claim that $h$ indeed maps to $S(n,\frac{-k}{n-})$. To show this we prove that $h(A)$ is a unit vector:
\begin{align*}
\langle h(A), h(A) \rangle &= \frac{1}{k(1-\frac{k}{n})}\langle \chi(A) - \frac{k}{n}\1, \chi(A) - \frac{k}{n}\1\rangle \\
&= \frac{n}{k(n-k)} [\langle \chi(A), \chi(A) \rangle - \langle \frac{k}{n}\1, \chi(A) \rangle -\langle \chi(A), \frac{k}{n}\1 \rangle + \frac{k^2}{n^2}\langle \1, \1\rangle]\\
&= \frac{n}{k(n-k)}[k - \frac{k^2}{n} - \frac{k^2}{n} + \frac{k^2}{n}] \\
&= \frac{n}{k(n-k)}[\frac{nk - k^2}{n}] \\
&= 1.
\end{align*}
Thus $h(A)$ is a unit vector in $\R^n$, that is a vertex of $S(n,\frac{-k}{n-k})$.
 We prove now that $h$ is a graph homomorphism. Let $A,B \in V(K(n,k))$ and suppose that $A\sim B$. Then $A\cap B = \emptyset$. More pertinently this means $\langle \chi(A), \chi(B) \rangle = 0$. Also observe that $\langle \chi(A), \1\rangle = k$ since $A$ is a $k$-subset of $\{1, \dots, n\}$. We need to show that $h(A) \sim h(B)$. Indeed we have:
\begin{align*}
\langle h(A), h(B) \rangle &= \langle  \frac{1}{\sqrt{k}\sqrt{1 - \frac{k}{n}}} (\chi(A) - \frac{k}{n} \1),  \frac{1}{\sqrt{k}\sqrt{1 - \frac{k}{n}}} (\chi(B) - \frac{k}{n} \1) \rangle \\
&= \frac{1}{k(1-\frac{k}{n})}[\langle \chi(A), \chi(B)\rangle + \langle \chi(A), \frac{-k}{n}\1\rangle + \langle \frac{-k}{n} \1, \chi(B) \rangle + \langle \frac{-k}{n} \1, \frac{-k}{n} \1\rangle] \\
&= \frac{n}{k(n-k)}[\frac{-k^2}{n} + \frac{-k^2}{n} + \frac{k^2}{n}] \\
&= \frac{-k}{n-k}.
\end{align*}
So $h(A) \sim h(B)$ by the definition of $S(n, \frac{-k}{n-k})$. Therefore $h$ is a homomorphism, and thus $K(n,k)$ has a vector $\frac{n}{k}$-colouring. $\blacksquare$
\section*{8}
\paragraph{}
Consider the program for $\theta(\overline{G})$:
\begin{align*}
\max sum(N) \label{eq:sum}\numberthis  \\
\ni tr(N) &= 1\\
N \circ (J - I - A) & =0 \\
N & \succcurlyeq 0
\end{align*}
and the program
\begin{align*}
\max \frac{1}{tr(N)} \label{eq:tr}\numberthis  \\
\ni sum(N) &= 1\\
N \circ (J - I - A) & =0 \\
N & \succcurlyeq 0.
\end{align*}
It is enough to show that the value of (\ref{eq:sum}) is equal to the value of (\ref{eq:tr}) to obtain that $\theta(\overline{G}) = $ value of (\ref{eq:tr}).
\paragraph{}
First we will show that  value of (\ref{eq:sum}) $\leq$ value of (\ref{eq:tr}). Let $N$ be an optimal solution to (\ref{eq:sum}). We observe that $e_1e_1^T$ is feasible for (\ref{eq:sum}) and hence $sum(N) \geq 1$. To see this observation note that $e_1e_1^T \succcurlyeq 0$, $tr(e_1e_1^T) = 1$, and (since $A_{ii}= 0$):
$$(e_1e_1^T) \circ (J- I - A) = e_1e_1^T - e_1e_1^T - 0 = 0.$$
We claim that $\frac{1}{\sum(N)} N$ is feasible for (\ref{eq:tr}) with objective value equal to the optimal value of (\ref{eq:sum}) and hence (\ref{eq:sum}) $\leq$ (\ref{eq:tr}) as desired. Indeed since  $\frac{1}{sum{N}} \geq 0$ and $N \succcurlyeq 0$, 
$$\frac{1}{sum(N)}N \succcurlyeq 0.$$
We also have $$sum(\frac{1}{sum(N)} N)= \frac{1}{sum(N)}sum(N) = 1.$$
And finally that
$$\frac{1}{sum(N)} N \circ (J - I - A) = \frac{1}{sum(N)} 0 = 0.$$
So $\frac{1}{sum(N)} N$ is feasible for (\ref{eq:tr}). Its objective value is
$$\frac{1}{tr(\frac{1}{sum(N)}N)} = \frac{sum(N)}{tr(N)} = sum(N)$$
which is the optimal value of (\ref{eq:sum}). Hence the value of (\ref{eq:sum}) $\leq$ the value of (\ref{eq:tr}).
\paragraph{}
We finish by showing that the value of (\ref{eq:tr}) $\leq$ value of (\ref{eq:sum}) and hence the values of the two programs are equal. Let $N$ be an optimal solution to (\ref{eq:tr}). We observe that $e_1e_1^T$ is feasible for (\ref{eq:tr}), and hence $\frac{1}{tr(N)} \geq 1$. As we have previously considered $e_1e_1^T$ it only remains to verify that
$$sum(e_1e_1^T) = 1$$
but this is clear. We claim that $\frac{1}{tr(N)} N$ is feasible for (\ref{eq:sum}) with objective value equal to the optimal value of (\ref{eq:tr}) and hence (\ref{eq:tr}) $\leq$ (\ref{eq:sum}) as desired. Indeed since $\frac{1}{tr(N)} \geq 0$ and $N\succcurlyeq 0$,
$$\frac{1}{tr(N)} N \succcurlyeq 0.$$
We also have $$tr(\frac{1}{tr(N)}N) = \frac{tr(N)}{tr(N)} = 1.$$
And finally that
$$\frac{1}{tr(N)} N \circ(J - I - A) = \frac{1}{tr(N)} 0 = 0.$$
So $\frac{1}{tr(N)}N$ is feasible for (\ref{eq:sum}). Its objective value is
$$sum(\frac{1}{tr(N)}N) = \frac{1}{tr(N)} sum(N) = \frac{1}{tr(N)}$$
which is the optimal value of (\ref{eq:tr}). Hence the value of (\ref{eq:tr}) $\leq$ the value of (\ref{eq:sum}).
\paragraph{}
Therefore the optimal values of (\ref{eq:sum}) and (\ref{eq:tr}) are equal and hence $\theta(\overline{G}) =$ value of (\ref{eq:tr}). $\blacksquare$
\section*{10}
\paragraph{}
Consider the inner product on polynomials
$$\langle f, g\rangle = \int_{-1}^1 f(t) g(t) dt.$$
Let $(g_i)i\geq 0$ be a sequence of orthogonal polynomials obtained by Gram-Schmidt from the sequence of powers of $t$. That is,
$$g_i(t) = t^i - \sum_{j=0}^{i-1} \frac{\langle t^i, g_j(t)\rangle}{\langle g_j(t), g_j(t)\rangle} g_j(t).$$
\paragraph{Lemma $10.1$}
For all $i$, $g_i$ has $i$ distinct odd roots of odd multiplicity in the interval $(-1,1)$.
\paragraph{Proof of Lemma $10.1$}
Let $i \geq 0$. Consider the polynomial $g_i$. Let $t_1, \dots, t_n$ be the distinct odd multiplicity roots in the interval $(-1,1)$. Suppose for a contradiction that $n < i$. Consider the polynomial $p(t)$ of the form
$$p(t) = (t-t_1)\cdot \dots \cdot(t-t_n)\cdot 1.$$
Then on the interval $(-1,1)$ the polynomial
$$g_i(t)p(t)$$
has all roots of even multiplicity. Thus $g_i(t)p(t)$ is an even function. Since Gram-Schmidt forms a basis, $g_i \neq 0$, and since $g_i(t)p(t)$ is even on $(-1, 1)$ implies $g_i(t)p(t)$ is not both $\geq 0$ and $\leq 0$ on the interval $(-1,1)$ we may conclude that
$$\int_{-1}^1 g_i(t)p(t) dt \neq 0.$$
But on the other hand, $p(t)$ is a polynomial of degree $n$ and so, since $g_0, \dots, g_{n}(t)$ form a basis of the space of polynomials of degree at most $n$, there exist $a_0, \dots, a_n$ such that
$$p(t) = \sum_{k=0}^n a_k g_k(t).$$
Now since $n < i$ we have for all $k \in \{0,\dots, n\}$
$$\langle g_i, g_k \rangle = 0$$
by Gram-Schmidt. Thus we see that
\begin{align*}
\int_{-1}^1 g_i(t)p_(t) dt &= \int_{-1}^1 g_i(\sum_{k=0}^n a_k g_k(t)) dt\\
&= \sum_{k=0}^n a_k \int_{-1}^1 g_i(t)g_k(t) dt\\
&= \sum_{k=0}^n a_k \langle g_i(t), g_k(t) \rangle\\
&= 0.\end{align*}
But this contradicts that the integral is non-zero. Hence $n \geq i$. But since $g_i(t)$ is a polynomial of degree $i$, $n \leq i$ and so $n=i$. That is $g_i(t)$ has $i$ distinct roots of odd multiplicity in the interval $(-1,1)$. $\blacksquare$
\paragraph{}
Let $p$ be a polynomial such that $p(t) \geq 0$ for all $t \in [-1,1]$, and $p$ divides $g_i$ for all $i \geq 1$. We compute $g_0$ and $g_1$. First $g_0$,
$$g_0 = t^0 = 1 $$
immediately. Now for $g_1$, we have that $\langle t, g_0 \rangle$ is $\int_{-1}^1 t dt = 1 - 1 = 0$, and so
$$g_1(t) = t - \frac{\langle t, 1\rangle}{\langle 1, 1\rangle} 1 = t.$$
Thus since $p$ divides $g_1$ we know $p$ divides $t$, and the degree of $p$ is at most $1$. But if $p$ is of degree $1$ there exists $a$ and $b$ such that $p$ is of the form
$$p(t) = at + b.$$
Since $p$ divides $t$ we can be a little stricter and say either $b=0$ or $a=0$. But if $b=0$ then $p(t) = at$ which changes sign at $0$ in the interval $[-1,1]$. This contradicts that $p(t) \geq 0$ on the interval $[-1,1]$. So $b \neq 0$ and hence $a=0$. That is, $p$ is a constant.
\paragraph{}
Now we deduce that $g_i(1) \neq 0$ for all $i$. But Lemma $10.1$ has already done all the work for us. The polynomial $g_i$ has at most $i$ roots, and by Lemma $10.1$, $g_i$ has $i$ roots in the interval $(-1,1)$. That is all $i$ roots of $g_i$ are accounted for. If $g_i$ had a root at $1$ it would have at least $i+1$ roots, a contradiction. $\blacksquare$
\end{document}
